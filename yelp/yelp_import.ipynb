{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from sqlalchemy import create_engine\n",
    "import sys"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Create engine (connecting to SQL)\n",
    "    postgresql+psycopg2://SQL_account_name(default:postgres):password@server_address(default:localhost:5432)/stat170-project"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "engine = create_engine('postgresql+psycopg2://postgres:QAZwsx123@localhost:5432/stat170-project')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## insert yelp shop info\n",
    "    It will take several minutes to insert data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[=                                       ] 6.5%"
     ]
    }
   ],
   "source": [
    "# read data\n",
    "data = pd.read_json(\".\\\\yelp_academic_dataset_business.json\",lines = True)\n",
    "# progress bar variables\n",
    "recored = 0\n",
    "progress = 0\n",
    "total = data.shape[0]\n",
    "\n",
    "# insert code\n",
    "for i in data.index:\n",
    "        # insert base info\n",
    "        values = [data.iloc[i].business_id,\n",
    "                data.iloc[i]['name'],\n",
    "                data.iloc[i].address,\n",
    "                data.iloc[i].city,\n",
    "                data.iloc[i].state,\n",
    "                data.iloc[i].postal_code,\n",
    "                data.iloc[i].latitude,\n",
    "                data.iloc[i].longitude,\n",
    "                data.iloc[i].stars,\n",
    "                int(data.iloc[i].review_count),\n",
    "                bool(data.iloc[i].is_open),\n",
    "                str(data.iloc[i].attributes),\n",
    "                str(data.iloc[i].hours)]\n",
    "        engine.execute(f\"INSERT INTO yelp_data.shop_info VALUES(%s, %s, %s, %s, %s, %s, %s, %s, %s, %s, %s, %s, %s)\\\n",
    "                        ON CONFLICT (business_id) DO UPDATA set name = excluded.name\",\n",
    "                values)\n",
    "        # insert categories\n",
    "        if data.iloc[i].categories:\n",
    "                list_cate = []\n",
    "                for category in data.iloc[i].categories.split(\", \"):\n",
    "                        list_cate.append((data.iloc[i].business_id, category))\n",
    "                engine.execute(f\"INSERT INTO yelp_data.shop_category VALUES(%s, %s)\\\n",
    "                        ON CONFLICT (business_id, category) DO UPDATE \\\n",
    "                        SET category = excluded.category\",\n",
    "                        list_cate)\n",
    "        # counter plus one\n",
    "        progress += 1\n",
    "        # refresh progress bar\n",
    "        if progress - recored >= total /1000:\n",
    "                sys.stdout.write('\\r')\n",
    "                sys.stdout.write(\"[{:40s}] {:.1f}%\".format('='*int(progress//(total/20)), progress/total*100))\n",
    "                recored = progress\n",
    "# print success info\n",
    "print(\"Inserting yelp shops' info DONE!\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## insert yelp reviews and other tables\n",
    "    WARNING: It will take a long time!!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "# read data\n",
    "import json\n",
    "\n",
    "# progress bar variables\n",
    "with open(\".\\\\yelp_academic_dataset_tip.json\",\"r\", encoding='utf-8') as f:\n",
    "    row = f.readline()\n",
    "    while row :\n",
    "        part_values = []\n",
    "        while row and len(part_values) <10000:\n",
    "            row = json.loads(row)\n",
    "            values = tuple(row.values())\n",
    "            part_values.append(values)\n",
    "            row = f.readline()\n",
    "        engine.execute(f\"INSERT INTO yelp_data.tip VALUES(%s, %s, %s, %s, %s)\\\n",
    "                        ON CONFLICT (user_id,business_id, date) DO NOTHING\",\n",
    "                part_values)\n",
    "print(\"finish inserting [tip]\")\n",
    "\n",
    "with open(\".\\\\yelp_academic_dataset_user.json\",\"r\", encoding='utf-8') as f:\n",
    "    row = f.readline()\n",
    "    while row :\n",
    "        part_values = []\n",
    "        while row and len(part_values) <10000:\n",
    "            row = json.loads(row)\n",
    "            values = tuple(row.values())\n",
    "            part_values.append(values)\n",
    "            row = f.readline()\n",
    "        engine.execute(f\"INSERT INTO yelp_data.user_info VALUES(%s, %s, %s, %s, %s,%s, %s, %s, %s, %s,%s, %s, %s, %s, %s,%s, %s, %s, %s, %s,%s,%s)\\\n",
    "                        ON CONFLICT (user_id) DO NOTHING\",\n",
    "                part_values)\n",
    "print(\"finish inserting [user]\")\n",
    "\n",
    "with open(\".\\\\yelp_academic_dataset_checkin.json\",\"r\", encoding='utf-8') as f:\n",
    "    row = f.readline()\n",
    "    while row :\n",
    "        part_values = []\n",
    "        while row and len(part_values) <10000:\n",
    "            row = json.loads(row)\n",
    "            values = tuple(row.values())\n",
    "            part_values.append(values)\n",
    "            row = f.readline()\n",
    "        engine.execute(f\"INSERT INTO yelp_data.checkin VALUES(%s, %s)\\\n",
    "                        ON CONFLICT (business_id) DO NOTHING\",\n",
    "                part_values)\n",
    "print(\"finish inserting [checkin]\")\n",
    "\n",
    "with open(\".\\\\photos.json\",\"r\", encoding='utf-8') as f:\n",
    "    row = f.readline()\n",
    "    while row :\n",
    "        part_values = []\n",
    "        while row and len(part_values) <10000:\n",
    "            row = json.loads(row)\n",
    "            values = tuple(row.values())\n",
    "            part_values.append(values)\n",
    "            row = f.readline()\n",
    "        engine.execute(f\"INSERT INTO yelp_data.photo VALUES(%s, %s, %s, %s)\\\n",
    "                        ON CONFLICT (photo_id) DO NOTHING\",\n",
    "                part_values)\n",
    "print(\"finish inserting [photo]\")\n",
    "\n",
    "recored = 0\n",
    "progress = 0\n",
    "total = 7013959\n",
    "with open(\".\\\\yelp_academic_dataset_review.json\",\"r\", encoding='utf-8') as f:\n",
    "    row = f.readline()\n",
    "    while row :\n",
    "        part_values = []\n",
    "        while row and len(part_values) <10000:\n",
    "            row = json.loads(row)\n",
    "            values = tuple(row.values())\n",
    "            part_values.append(values)\n",
    "            row = f.readline()\n",
    "        engine.execute(f\"INSERT INTO yelp_data.review VALUES(%s, %s, %s, %s, %s, %s, %s, %s, %s)\\\n",
    "                        ON CONFLICT (review_id) DO NOTHING\",\n",
    "                part_values)\n",
    "\n",
    "        # counter plus one\n",
    "        progress += 10000\n",
    "        # refresh progress bar\n",
    "        if progress - recored >= total /1000:\n",
    "                sys.stdout.write('\\r')\n",
    "                sys.stdout.write(\"inserting reviews: [{:40s}] {:.1f}%\".format('='*int(progress//(total/20)), progress/total*100))\n",
    "                recored = progress"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Extra Part: convert json to csv\n",
    "    The output files have encoding error when input into the SQL."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{\"photo_id\": \"zsvj7vloL4L5jhYyPIuVwg\", \"business_id\": \"Nk-SJhPlDBkAZvfsADtccA\", \"caption\": \"Nice rock artwork everywhere and craploads of taps.\", \"label\": \"inside\"}\n",
      "\n",
      "finish inserting [photo]\n"
     ]
    }
   ],
   "source": [
    "# exploring the attributes in each tables\n",
    "\n",
    "'''\n",
    "with open(\".\\\\photos.json\",\"r\", encoding='utf-8') as f:\n",
    "    print(f.readline())\n",
    "'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "# convert to csv\n",
    "import csv\n",
    "import json\n",
    "dataset = ['business','review','checkin','tip','user']\n",
    "for i in dataset:\n",
    "    f = open(f\"C:\\\\Users\\\\kev\\\\Downloads\\\\yelp_dataset-1\\\\yelp_academic_dataset_{i}.json\",\"rb\")\n",
    "    with open(f\"C:\\\\Users\\\\kev\\\\Downloads\\\\yelp_dataset-1\\\\yelp_academic_dataset_{i}.csv\",\"w\", encoding='utf-8',newline='') as file:\n",
    "        csv_w = csv.writer(file)\n",
    "\n",
    "        row = f.readline()\n",
    "        row = json.loads(row)\n",
    "        csv_w.writerow(list(row.keys()))\n",
    "\n",
    "        row = f.readline()\n",
    "        while row:\n",
    "            row = json.loads(row)\n",
    "            row = list(row.values())\n",
    "            csv_w.writerow(row)\n",
    "            row = f.readline()\n",
    "\n",
    "        f.close()\n",
    "\"\"\""
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "07efdcd4b820c98a756949507a4d29d7862823915ec7477944641bea022f4f62"
  },
  "kernelspec": {
   "display_name": "Python 3.8.5 ('base')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
