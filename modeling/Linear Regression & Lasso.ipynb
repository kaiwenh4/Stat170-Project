{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# https://machinelearningmastery.com/arima-for-time-series-forecasting-with-python/\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sqlalchemy import create_engine"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# load data\n",
    "engine_out = create_engine(r'postgresql+psycopg2://postgres:stats170@104.197.51.5')\n",
    "sql = '''SELECT * FROM yelp_data.shop_static_info;'''\n",
    "shop_static_info = pd.read_sql_query(sql,con=engine_out)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>business_id</th>\n",
       "      <th>stars</th>\n",
       "      <th>rate_user_num</th>\n",
       "      <th>state</th>\n",
       "      <th>latitude</th>\n",
       "      <th>longitude</th>\n",
       "      <th>review_count</th>\n",
       "      <th>price_level</th>\n",
       "      <th>HasTV</th>\n",
       "      <th>Caters</th>\n",
       "      <th>...</th>\n",
       "      <th>class_74</th>\n",
       "      <th>class_75</th>\n",
       "      <th>class_76</th>\n",
       "      <th>class_77</th>\n",
       "      <th>class_79</th>\n",
       "      <th>class_8</th>\n",
       "      <th>class_9</th>\n",
       "      <th>avg_review_useful</th>\n",
       "      <th>avg_review_funny</th>\n",
       "      <th>avg_review_cool</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>00rY5F9ltW-IWf2Ev96kOg</td>\n",
       "      <td>4.517730</td>\n",
       "      <td>282</td>\n",
       "      <td>IN</td>\n",
       "      <td>39.779133</td>\n",
       "      <td>-86.164525</td>\n",
       "      <td>277.0</td>\n",
       "      <td>2.00</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>1.042553</td>\n",
       "      <td>0.148936</td>\n",
       "      <td>0.769504</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>00sOoojttpdZljH8VgOU0A</td>\n",
       "      <td>3.294118</td>\n",
       "      <td>17</td>\n",
       "      <td>FL</td>\n",
       "      <td>27.996322</td>\n",
       "      <td>-82.372662</td>\n",
       "      <td>17.0</td>\n",
       "      <td>1.00</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2.764706</td>\n",
       "      <td>1.294118</td>\n",
       "      <td>1.941176</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>018SgjILDCKLR7gFSEkbGQ</td>\n",
       "      <td>4.555556</td>\n",
       "      <td>9</td>\n",
       "      <td>TN</td>\n",
       "      <td>35.908767</td>\n",
       "      <td>-86.884391</td>\n",
       "      <td>9.0</td>\n",
       "      <td>1.39</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1.111111</td>\n",
       "      <td>0.222222</td>\n",
       "      <td>0.444444</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>02nb6CI8w-2EoSEkQdk2Wg</td>\n",
       "      <td>4.161905</td>\n",
       "      <td>105</td>\n",
       "      <td>PA</td>\n",
       "      <td>39.936170</td>\n",
       "      <td>-75.146942</td>\n",
       "      <td>101.0</td>\n",
       "      <td>1.00</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.685714</td>\n",
       "      <td>0.276190</td>\n",
       "      <td>0.390476</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>02nUjwVmJGTgGyiIi-hklg</td>\n",
       "      <td>4.545455</td>\n",
       "      <td>11</td>\n",
       "      <td>PA</td>\n",
       "      <td>39.952512</td>\n",
       "      <td>-75.171742</td>\n",
       "      <td>11.0</td>\n",
       "      <td>1.39</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2.909091</td>\n",
       "      <td>0.363636</td>\n",
       "      <td>1.181818</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6239</th>\n",
       "      <td>zznJox6-nmXlGYNWgTDwQQ</td>\n",
       "      <td>1.633333</td>\n",
       "      <td>30</td>\n",
       "      <td>FL</td>\n",
       "      <td>27.990058</td>\n",
       "      <td>-82.730226</td>\n",
       "      <td>30.0</td>\n",
       "      <td>1.00</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.333333</td>\n",
       "      <td>0.033333</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6240</th>\n",
       "      <td>ZzqqkL9mHsOnFHJvVd-10Q</td>\n",
       "      <td>3.945946</td>\n",
       "      <td>37</td>\n",
       "      <td>NJ</td>\n",
       "      <td>39.927515</td>\n",
       "      <td>-74.953437</td>\n",
       "      <td>36.0</td>\n",
       "      <td>1.00</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.837838</td>\n",
       "      <td>0.648649</td>\n",
       "      <td>0.648649</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6241</th>\n",
       "      <td>zZrDoiQIUmiVkifJx0h_KA</td>\n",
       "      <td>4.375000</td>\n",
       "      <td>8</td>\n",
       "      <td>CA</td>\n",
       "      <td>34.423056</td>\n",
       "      <td>-119.704515</td>\n",
       "      <td>8.0</td>\n",
       "      <td>1.39</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>9.625000</td>\n",
       "      <td>3.875000</td>\n",
       "      <td>8.375000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6242</th>\n",
       "      <td>zzXRdzrVhfNWPHD2MeyWeA</td>\n",
       "      <td>2.066667</td>\n",
       "      <td>15</td>\n",
       "      <td>PA</td>\n",
       "      <td>40.245754</td>\n",
       "      <td>-75.342402</td>\n",
       "      <td>14.0</td>\n",
       "      <td>1.39</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1.333333</td>\n",
       "      <td>0.333333</td>\n",
       "      <td>0.666667</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6243</th>\n",
       "      <td>zZ_xsIQfotnHe25MxQyg0g</td>\n",
       "      <td>2.213115</td>\n",
       "      <td>61</td>\n",
       "      <td>MO</td>\n",
       "      <td>38.626700</td>\n",
       "      <td>-90.335488</td>\n",
       "      <td>59.0</td>\n",
       "      <td>1.00</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.672131</td>\n",
       "      <td>0.393443</td>\n",
       "      <td>0.295082</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>6244 rows × 166 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                 business_id     stars  rate_user_num state   latitude  \\\n",
       "0     00rY5F9ltW-IWf2Ev96kOg  4.517730            282    IN  39.779133   \n",
       "1     00sOoojttpdZljH8VgOU0A  3.294118             17    FL  27.996322   \n",
       "2     018SgjILDCKLR7gFSEkbGQ  4.555556              9    TN  35.908767   \n",
       "3     02nb6CI8w-2EoSEkQdk2Wg  4.161905            105    PA  39.936170   \n",
       "4     02nUjwVmJGTgGyiIi-hklg  4.545455             11    PA  39.952512   \n",
       "...                      ...       ...            ...   ...        ...   \n",
       "6239  zznJox6-nmXlGYNWgTDwQQ  1.633333             30    FL  27.990058   \n",
       "6240  ZzqqkL9mHsOnFHJvVd-10Q  3.945946             37    NJ  39.927515   \n",
       "6241  zZrDoiQIUmiVkifJx0h_KA  4.375000              8    CA  34.423056   \n",
       "6242  zzXRdzrVhfNWPHD2MeyWeA  2.066667             15    PA  40.245754   \n",
       "6243  zZ_xsIQfotnHe25MxQyg0g  2.213115             61    MO  38.626700   \n",
       "\n",
       "       longitude  review_count  price_level  HasTV  Caters  ...  class_74  \\\n",
       "0     -86.164525         277.0         2.00      0       0  ...       0.0   \n",
       "1     -82.372662          17.0         1.00      2       0  ...       0.0   \n",
       "2     -86.884391           9.0         1.39      2       0  ...       NaN   \n",
       "3     -75.146942         101.0         1.00      2       0  ...       0.0   \n",
       "4     -75.171742          11.0         1.39      2       2  ...       0.0   \n",
       "...          ...           ...          ...    ...     ...  ...       ...   \n",
       "6239  -82.730226          30.0         1.00      2       2  ...       0.0   \n",
       "6240  -74.953437          36.0         1.00      2       0  ...       0.0   \n",
       "6241 -119.704515           8.0         1.39      2       2  ...       0.0   \n",
       "6242  -75.342402          14.0         1.39      1       2  ...       NaN   \n",
       "6243  -90.335488          59.0         1.00      1       0  ...       0.0   \n",
       "\n",
       "      class_75  class_76  class_77  class_79  class_8  class_9  \\\n",
       "0          0.0       0.0       0.0       0.0      0.0      2.0   \n",
       "1          0.0       0.0       0.0       0.0      0.0      0.0   \n",
       "2          NaN       NaN       NaN       NaN      NaN      NaN   \n",
       "3          0.0       0.0       0.0       0.0      0.0      0.0   \n",
       "4          2.0       0.0       0.0       0.0      0.0      0.0   \n",
       "...        ...       ...       ...       ...      ...      ...   \n",
       "6239       0.0       0.0       0.0       0.0      0.0      0.0   \n",
       "6240       0.0       0.0       0.0       0.0      0.0      0.0   \n",
       "6241       0.0       0.0       0.0       0.0      0.0      0.0   \n",
       "6242       NaN       NaN       NaN       NaN      NaN      NaN   \n",
       "6243       0.0       0.0       0.0       0.0      0.0      0.0   \n",
       "\n",
       "      avg_review_useful  avg_review_funny  avg_review_cool  \n",
       "0              1.042553          0.148936         0.769504  \n",
       "1              2.764706          1.294118         1.941176  \n",
       "2              1.111111          0.222222         0.444444  \n",
       "3              0.685714          0.276190         0.390476  \n",
       "4              2.909091          0.363636         1.181818  \n",
       "...                 ...               ...              ...  \n",
       "6239           0.333333          0.033333         0.000000  \n",
       "6240           0.837838          0.648649         0.648649  \n",
       "6241           9.625000          3.875000         8.375000  \n",
       "6242           1.333333          0.333333         0.666667  \n",
       "6243           0.672131          0.393443         0.295082  \n",
       "\n",
       "[6244 rows x 166 columns]"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "shop_static_info"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "D:\\Anaconda\\lib\\site-packages\\statsmodels\\tsa\\base\\tsa_model.py:7: FutureWarning: pandas.Int64Index is deprecated and will be removed from pandas in a future version. Use pandas.Index with the appropriate dtype instead.\n",
      "  from pandas import (to_datetime, Int64Index, DatetimeIndex, Period,\n",
      "D:\\Anaconda\\lib\\site-packages\\statsmodels\\tsa\\base\\tsa_model.py:7: FutureWarning: pandas.Float64Index is deprecated and will be removed from pandas in a future version. Use pandas.Index with the appropriate dtype instead.\n",
      "  from pandas import (to_datetime, Int64Index, DatetimeIndex, Period,\n"
     ]
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import statsmodels.api as sm\n",
    "from scipy import stats\n",
    "import statsmodels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# fit model\n",
    "'''\n",
    "Y variable is weighted rating\n",
    "'''\n",
    "# Fit a linear regression\n",
    "X = shop_static_info[[\n",
    "    'stars', \n",
    "    'rate_user_num', \n",
    "    'state', \n",
    "    'latitude',\n",
    "    'longitude', \n",
    "    'review_count', \n",
    "    'price_level', \n",
    "    'HasTV', \n",
    "    'Caters', \n",
    "    'OutdoorSeating', \n",
    "    'WheelchairAccessible', \n",
    "    'BusinessParking', \n",
    "    'RestaurantsDelivery', \n",
    "    'BikeParking', \n",
    "    'WiFi', \n",
    "    'Alcohol', \n",
    "    'RestaurantsTakeOut',\n",
    "    'BusinessAcceptsCreditCards', \n",
    "    'open_days', \n",
    "    'open_hours', \n",
    "    'rating', \n",
    "    'num_rating', \n",
    "    'photo_drink', \n",
    "    'photo_food', \n",
    "    'photo_inside', \n",
    "    'photo_menu',\n",
    "    'photo_outside', \n",
    "    'photo_total', \n",
    "    'user_avg_stars', \n",
    "    'user_avg_review_count', \n",
    "    'user_avg_useful', \n",
    "    'user_avg_funny', \n",
    "    'user_avg_cool', \n",
    "    'user_avg_fans', \n",
    "    'user_avg_compliment_hot', \n",
    "    'user_avg_compliment_more', \n",
    "    'user_avg_compliment_profile', \n",
    "    'user_avg_compliment_cute', \n",
    "    'user_avg_compliment_list', \n",
    "    'user_avg_compliment_note', \n",
    "    'user_avg_compliment_plain', \n",
    "    'user_avg_compliment_cool',\n",
    "    'user_avg_compliment_funny', \n",
    "    'user_avg_compliment_writer', \n",
    "    'user_avg_compliment_photos', \n",
    "    'user_yelp_years', \n",
    "    'user_avg_total_compliment',\n",
    "    'state_state', \n",
    "    'abbrev',\n",
    "    'code', \n",
    "    'full_state',\n",
    "    'Total:_Estimate',\n",
    "    'Less than $20,000_Estimate', \n",
    "    '$20,000 to $39,999_Estimate', \n",
    "    '$40,000 to $59,999_Estimate', \n",
    "    '$60,000 to $99,999_Estimate', \n",
    "    '$100,000 to $149,999_Estimate',\n",
    "    '$150,000 to $199,999_Estimate', \n",
    "    '$200,000 or more_Estimate', \n",
    "    'PAYANN', 'PCHDAPR', 'PCHADVT', 'DENSITY_2021', 'POP_2021', \n",
    "    'Total:_max', 'Less than $20,000_max', '$20,000 to $39,999_max', '$40,000 to $59,999_max', \n",
    "    '$60,000 to $99,999_max', '$100,000 to $149,999_max', '$150,000 to $199,999_max', '$200,000 or more_max',\n",
    "    'Total:_min', 'Less than $20,000_min', '$20,000 to $39,999_min', '$40,000 to $59,999_min', \n",
    "    '$60,000 to $99,999_min', '$100,000 to $149,999_min', '$150,000 to $199,999_min', '$200,000 or more_min', \n",
    "    'less_100m', 'less_500m', 'less_1km', 'less_5km', 'less_10km', 'less_50km', \n",
    "    'class_0', 'class_1', 'class_10', 'class_11', 'class_12', 'class_13', 'class_14', 'class_15', \n",
    "    'class_16', 'class_17', 'class_2', 'class_20', 'class_22', 'class_23', 'class_24', 'class_25', \n",
    "    'class_26', 'class_27', 'class_28', 'class_29', 'class_3', 'class_31', 'class_32', 'class_33', \n",
    "    'class_34', 'class_35', 'class_36', 'class_37', 'class_38', 'class_39', 'class_4', 'class_40', \n",
    "    'class_41', 'class_42', 'class_43', 'class_44', 'class_45', 'class_46', 'class_47', 'class_48', \n",
    "    'class_49', 'class_5', 'class_50', 'class_51', 'class_52', 'class_53', 'class_54', 'class_55', \n",
    "    'class_56', 'class_57', 'class_58', 'class_59', 'class_6', 'class_60', 'class_61', 'class_62', \n",
    "    'class_63', 'class_64', 'class_65', 'class_66', 'class_67', 'class_68', 'class_69', 'class_7', \n",
    "    'class_70', 'class_71', 'class_72', 'class_73', 'class_74', 'class_75', 'class_76', 'class_77', \n",
    "    'class_79', 'class_8', 'class_9'\n",
    "]] \n",
    "y = shop_static_info[ 'weighted_rating']\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<ipython-input-6-c4424b00ebc0>:1: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  X['user_yelp_years'] = X['user_yelp_years'] / np.timedelta64(1, 's')\n",
      "<ipython-input-6-c4424b00ebc0>:4: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  X[i] = pd.factorize(X[i])[0]\n",
      "<ipython-input-6-c4424b00ebc0>:6: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  X.replace([np.inf, -np.inf], 0, inplace=True)\n",
      "<ipython-input-6-c4424b00ebc0>:7: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  X.replace(np.nan, 0, inplace=True)\n",
      "D:\\Anaconda\\lib\\site-packages\\statsmodels\\tsa\\tsatools.py:142: FutureWarning: In a future version of pandas all arguments of concat except for the argument 'objs' will be keyword-only.\n",
      "  x = pd.concat(x[::order], 1)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<table class=\"simpletable\">\n",
       "<caption>OLS Regression Results</caption>\n",
       "<tr>\n",
       "  <th>Dep. Variable:</th>     <td>weighted_rating</td> <th>  R-squared:         </th> <td>   0.761</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Model:</th>                   <td>OLS</td>       <th>  Adj. R-squared:    </th> <td>   0.756</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Method:</th>             <td>Least Squares</td>  <th>  F-statistic:       </th> <td>   149.4</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Date:</th>             <td>Sat, 21 May 2022</td> <th>  Prob (F-statistic):</th>  <td>  0.00</td> \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Time:</th>                 <td>10:54:14</td>     <th>  Log-Likelihood:    </th> <td> -651.33</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>No. Observations:</th>      <td>  6244</td>      <th>  AIC:               </th> <td>   1565.</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Df Residuals:</th>          <td>  6113</td>      <th>  BIC:               </th> <td>   2448.</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Df Model:</th>              <td>   130</td>      <th>                     </th>     <td> </td>   \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Covariance Type:</th>      <td>nonrobust</td>    <th>                     </th>     <td> </td>   \n",
       "</tr>\n",
       "</table>\n",
       "<table class=\"simpletable\">\n",
       "<tr>\n",
       "                <td></td>                   <th>coef</th>     <th>std err</th>      <th>t</th>      <th>P>|t|</th>  <th>[0.025</th>    <th>0.975]</th>  \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>const</th>                         <td>-5.801e-09</td> <td> 1.37e-07</td> <td>   -0.042</td> <td> 0.966</td> <td>-2.74e-07</td> <td> 2.63e-07</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>stars</th>                         <td>    0.4086</td> <td>    0.008</td> <td>   52.292</td> <td> 0.000</td> <td>    0.393</td> <td>    0.424</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>rate_user_num</th>                 <td>   -0.0034</td> <td>    0.001</td> <td>   -2.596</td> <td> 0.009</td> <td>   -0.006</td> <td>   -0.001</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>state</th>                         <td> 2.551e-07</td> <td> 1.38e-07</td> <td>    1.843</td> <td> 0.065</td> <td>-1.62e-08</td> <td> 5.26e-07</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>latitude</th>                      <td>    0.0162</td> <td>    0.036</td> <td>    0.456</td> <td> 0.648</td> <td>   -0.053</td> <td>    0.086</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>longitude</th>                     <td>    0.0566</td> <td>    0.029</td> <td>    1.963</td> <td> 0.050</td> <td> 6.76e-05</td> <td>    0.113</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>review_count</th>                  <td>    0.0032</td> <td>    0.001</td> <td>    2.409</td> <td> 0.016</td> <td>    0.001</td> <td>    0.006</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>price_level</th>                   <td>    0.0094</td> <td>    0.008</td> <td>    1.198</td> <td> 0.231</td> <td>   -0.006</td> <td>    0.025</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>HasTV</th>                         <td>    0.0374</td> <td>    0.006</td> <td>    6.681</td> <td> 0.000</td> <td>    0.026</td> <td>    0.048</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Caters</th>                        <td>   -0.0072</td> <td>    0.005</td> <td>   -1.524</td> <td> 0.128</td> <td>   -0.017</td> <td>    0.002</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>OutdoorSeating</th>                <td>   -0.0216</td> <td>    0.006</td> <td>   -3.846</td> <td> 0.000</td> <td>   -0.033</td> <td>   -0.011</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>WheelchairAccessible</th>          <td>    0.0051</td> <td>    0.008</td> <td>    0.630</td> <td> 0.529</td> <td>   -0.011</td> <td>    0.021</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>BusinessParking</th>               <td>    0.0060</td> <td>    0.008</td> <td>    0.718</td> <td> 0.473</td> <td>   -0.010</td> <td>    0.022</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>RestaurantsDelivery</th>           <td>    0.0107</td> <td>    0.006</td> <td>    1.863</td> <td> 0.063</td> <td>   -0.001</td> <td>    0.022</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>BikeParking</th>                   <td>    0.0142</td> <td>    0.007</td> <td>    2.152</td> <td> 0.031</td> <td>    0.001</td> <td>    0.027</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>WiFi</th>                          <td>   -0.0014</td> <td>    0.007</td> <td>   -0.193</td> <td> 0.847</td> <td>   -0.016</td> <td>    0.013</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Alcohol</th>                       <td>   -0.0014</td> <td>    0.007</td> <td>   -0.193</td> <td> 0.847</td> <td>   -0.016</td> <td>    0.013</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>RestaurantsTakeOut</th>            <td>   -0.0060</td> <td>    0.010</td> <td>   -0.580</td> <td> 0.562</td> <td>   -0.026</td> <td>    0.014</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>BusinessAcceptsCreditCards</th>    <td>   -0.0014</td> <td>    0.013</td> <td>   -0.109</td> <td> 0.914</td> <td>   -0.027</td> <td>    0.024</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>open_days</th>                     <td>    0.0149</td> <td>    0.003</td> <td>    5.756</td> <td> 0.000</td> <td>    0.010</td> <td>    0.020</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>open_hours</th>                    <td>   -0.0010</td> <td>    0.000</td> <td>   -9.137</td> <td> 0.000</td> <td>   -0.001</td> <td>   -0.001</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>rating</th>                        <td>    0.1685</td> <td>    0.004</td> <td>   41.189</td> <td> 0.000</td> <td>    0.160</td> <td>    0.176</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>num_rating</th>                    <td> 4.993e-05</td> <td> 4.44e-06</td> <td>   11.245</td> <td> 0.000</td> <td> 4.12e-05</td> <td> 5.86e-05</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>photo_drink</th>                   <td>    0.0123</td> <td>    0.004</td> <td>    2.741</td> <td> 0.006</td> <td>    0.003</td> <td>    0.021</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>photo_food</th>                    <td>    0.0011</td> <td>    0.004</td> <td>    0.290</td> <td> 0.772</td> <td>   -0.006</td> <td>    0.008</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>photo_inside</th>                  <td>   -0.0009</td> <td>    0.004</td> <td>   -0.242</td> <td> 0.809</td> <td>   -0.008</td> <td>    0.007</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>photo_menu</th>                    <td>   -0.0127</td> <td>    0.016</td> <td>   -0.786</td> <td> 0.432</td> <td>   -0.044</td> <td>    0.019</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>photo_outside</th>                 <td>   -0.0027</td> <td>    0.006</td> <td>   -0.444</td> <td> 0.657</td> <td>   -0.015</td> <td>    0.009</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>photo_total</th>                   <td>   -0.0029</td> <td>    0.004</td> <td>   -0.741</td> <td> 0.459</td> <td>   -0.011</td> <td>    0.005</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>user_avg_stars</th>                <td>   -0.0479</td> <td>    0.018</td> <td>   -2.710</td> <td> 0.007</td> <td>   -0.083</td> <td>   -0.013</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>user_avg_review_count</th>         <td>   -0.0002</td> <td> 5.03e-05</td> <td>   -4.167</td> <td> 0.000</td> <td>   -0.000</td> <td>   -0.000</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>user_avg_useful</th>               <td> 1.285e-05</td> <td> 4.05e-05</td> <td>    0.318</td> <td> 0.751</td> <td>-6.65e-05</td> <td> 9.22e-05</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>user_avg_funny</th>                <td> 1.257e-05</td> <td> 2.77e-05</td> <td>    0.453</td> <td> 0.650</td> <td>-4.18e-05</td> <td> 6.69e-05</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>user_avg_cool</th>                 <td> 1.502e-05</td> <td> 5.19e-05</td> <td>    0.289</td> <td> 0.772</td> <td>-8.67e-05</td> <td>    0.000</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>user_avg_fans</th>                 <td>   -0.0003</td> <td>    0.000</td> <td>   -1.073</td> <td> 0.284</td> <td>   -0.001</td> <td>    0.000</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>user_avg_compliment_hot</th>       <td>   -0.0004</td> <td>    0.000</td> <td>   -1.083</td> <td> 0.279</td> <td>   -0.001</td> <td>    0.000</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>user_avg_compliment_more</th>      <td>    0.0033</td> <td>    0.003</td> <td>    1.267</td> <td> 0.205</td> <td>   -0.002</td> <td>    0.008</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>user_avg_compliment_profile</th>   <td>   -0.0047</td> <td>    0.002</td> <td>   -1.970</td> <td> 0.049</td> <td>   -0.009</td> <td> -2.4e-05</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>user_avg_compliment_cute</th>      <td>   -0.0022</td> <td>    0.003</td> <td>   -0.801</td> <td> 0.423</td> <td>   -0.008</td> <td>    0.003</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>user_avg_compliment_list</th>      <td>    0.0096</td> <td>    0.004</td> <td>    2.439</td> <td> 0.015</td> <td>    0.002</td> <td>    0.017</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>user_avg_compliment_note</th>      <td>   -0.0007</td> <td>    0.000</td> <td>   -3.481</td> <td> 0.001</td> <td>   -0.001</td> <td>   -0.000</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>user_avg_compliment_plain</th>     <td>   -0.0005</td> <td>    0.000</td> <td>   -2.638</td> <td> 0.008</td> <td>   -0.001</td> <td>   -0.000</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>user_avg_compliment_cool</th>      <td>   -0.0009</td> <td>    0.000</td> <td>   -3.561</td> <td> 0.000</td> <td>   -0.001</td> <td>   -0.000</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>user_avg_compliment_funny</th>     <td>   -0.0009</td> <td>    0.000</td> <td>   -3.561</td> <td> 0.000</td> <td>   -0.001</td> <td>   -0.000</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>user_avg_compliment_writer</th>    <td>   -0.0009</td> <td>    0.000</td> <td>   -2.167</td> <td> 0.030</td> <td>   -0.002</td> <td>-8.56e-05</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>user_avg_compliment_photos</th>    <td>   -0.0009</td> <td>    0.000</td> <td>   -3.757</td> <td> 0.000</td> <td>   -0.001</td> <td>   -0.000</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>user_yelp_years</th>               <td>-3.192e-10</td> <td> 9.43e-11</td> <td>   -3.386</td> <td> 0.001</td> <td>-5.04e-10</td> <td>-1.34e-10</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>user_avg_total_compliment</th>     <td>    0.0007</td> <td>    0.000</td> <td>    3.552</td> <td> 0.000</td> <td>    0.000</td> <td>    0.001</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>state_state</th>                   <td> 2.548e-07</td> <td> 1.38e-07</td> <td>    1.841</td> <td> 0.066</td> <td>-1.64e-08</td> <td> 5.26e-07</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>abbrev</th>                        <td> 2.548e-07</td> <td> 1.38e-07</td> <td>    1.841</td> <td> 0.066</td> <td>-1.64e-08</td> <td> 5.26e-07</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>code</th>                          <td> 2.548e-07</td> <td> 1.38e-07</td> <td>    1.841</td> <td> 0.066</td> <td>-1.64e-08</td> <td> 5.26e-07</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>full_state</th>                    <td> 2.548e-07</td> <td> 1.38e-07</td> <td>    1.841</td> <td> 0.066</td> <td>-1.64e-08</td> <td> 5.26e-07</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Total:_Estimate</th>               <td>-2.958e-06</td> <td> 1.73e-06</td> <td>   -1.711</td> <td> 0.087</td> <td>-6.35e-06</td> <td> 4.32e-07</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Less than $20,000_Estimate</th>    <td>-1.509e-05</td> <td> 7.26e-06</td> <td>   -2.077</td> <td> 0.038</td> <td>-2.93e-05</td> <td> -8.5e-07</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>$20,000 to $39,999_Estimate</th>   <td> 4.604e-06</td> <td> 4.44e-06</td> <td>    1.037</td> <td> 0.300</td> <td> -4.1e-06</td> <td> 1.33e-05</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>$40,000 to $59,999_Estimate</th>   <td>-3.731e-06</td> <td> 6.27e-06</td> <td>   -0.595</td> <td> 0.552</td> <td> -1.6e-05</td> <td> 8.55e-06</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>$60,000 to $99,999_Estimate</th>   <td>  1.48e-05</td> <td> 9.46e-06</td> <td>    1.565</td> <td> 0.118</td> <td>-3.74e-06</td> <td> 3.33e-05</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>$100,000 to $149,999_Estimate</th> <td>-2.325e-05</td> <td> 1.16e-05</td> <td>   -2.001</td> <td> 0.045</td> <td> -4.6e-05</td> <td>-4.68e-07</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>$150,000 to $199,999_Estimate</th> <td> 2.616e-05</td> <td> 1.17e-05</td> <td>    2.231</td> <td> 0.026</td> <td> 3.17e-06</td> <td> 4.91e-05</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>$200,000 or more_Estimate</th>     <td>-6.452e-06</td> <td> 3.24e-06</td> <td>   -1.989</td> <td> 0.047</td> <td>-1.28e-05</td> <td>-9.25e-08</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>PAYANN</th>                        <td> 1.031e-06</td> <td> 7.26e-07</td> <td>    1.421</td> <td> 0.155</td> <td>-3.92e-07</td> <td> 2.45e-06</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>PCHDAPR</th>                       <td>-7.886e-05</td> <td> 5.29e-05</td> <td>   -1.492</td> <td> 0.136</td> <td>   -0.000</td> <td> 2.48e-05</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>PCHADVT</th>                       <td>    0.0002</td> <td>    0.000</td> <td>    1.782</td> <td> 0.075</td> <td>-2.29e-05</td> <td>    0.000</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>DENSITY_2021</th>                  <td>-1.667e-05</td> <td> 1.45e-05</td> <td>   -1.148</td> <td> 0.251</td> <td>-4.51e-05</td> <td> 1.18e-05</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>POP_2021</th>                      <td> 3.473e-06</td> <td> 1.82e-06</td> <td>    1.903</td> <td> 0.057</td> <td>-1.04e-07</td> <td> 7.05e-06</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Total:_max</th>                    <td> 5.923e-05</td> <td> 3.27e-05</td> <td>    1.812</td> <td> 0.070</td> <td>-4.85e-06</td> <td>    0.000</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Less than $20,000_max</th>         <td>-4.606e-05</td> <td> 3.94e-05</td> <td>   -1.169</td> <td> 0.242</td> <td>   -0.000</td> <td> 3.12e-05</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>$20,000 to $39,999_max</th>        <td> 6.337e-05</td> <td> 3.45e-05</td> <td>    1.839</td> <td> 0.066</td> <td>-4.19e-06</td> <td>    0.000</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>$40,000 to $59,999_max</th>        <td>    0.0001</td> <td> 7.82e-05</td> <td>    1.795</td> <td> 0.073</td> <td>-1.29e-05</td> <td>    0.000</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>$60,000 to $99,999_max</th>        <td>    0.0002</td> <td>    0.000</td> <td>    1.737</td> <td> 0.082</td> <td>-2.36e-05</td> <td>    0.000</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>$100,000 to $149,999_max</th>      <td> 5.427e-05</td> <td> 3.77e-05</td> <td>    1.440</td> <td> 0.150</td> <td>-1.96e-05</td> <td>    0.000</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>$150,000 to $199,999_max</th>      <td> 4.007e-05</td> <td>  1.5e-05</td> <td>    2.671</td> <td> 0.008</td> <td> 1.07e-05</td> <td> 6.95e-05</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>$200,000 or more_max</th>          <td>-4.933e-06</td> <td> 1.78e-05</td> <td>   -0.277</td> <td> 0.782</td> <td>-3.99e-05</td> <td>    3e-05</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Total:_min</th>                    <td>-6.514e-05</td> <td> 3.61e-05</td> <td>   -1.803</td> <td> 0.071</td> <td>   -0.000</td> <td> 5.69e-06</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Less than $20,000_min</th>         <td> 1.588e-05</td> <td> 2.92e-05</td> <td>    0.545</td> <td> 0.586</td> <td>-4.13e-05</td> <td>  7.3e-05</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>$20,000 to $39,999_min</th>        <td>-5.416e-05</td> <td> 2.78e-05</td> <td>   -1.945</td> <td> 0.052</td> <td>   -0.000</td> <td> 4.29e-07</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>$40,000 to $59,999_min</th>        <td>   -0.0001</td> <td> 8.07e-05</td> <td>   -1.833</td> <td> 0.067</td> <td>   -0.000</td> <td> 1.03e-05</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>$60,000 to $99,999_min</th>        <td>   -0.0002</td> <td> 8.97e-05</td> <td>   -1.719</td> <td> 0.086</td> <td>   -0.000</td> <td> 2.17e-05</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>$100,000 to $149,999_min</th>      <td>   -0.0001</td> <td> 5.83e-05</td> <td>   -1.729</td> <td> 0.084</td> <td>   -0.000</td> <td> 1.35e-05</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>$150,000 to $199,999_min</th>      <td> 1.225e-05</td> <td> 1.31e-05</td> <td>    0.938</td> <td> 0.348</td> <td>-1.34e-05</td> <td> 3.79e-05</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>$200,000 or more_min</th>          <td>-7.971e-06</td> <td> 1.72e-05</td> <td>   -0.464</td> <td> 0.642</td> <td>-4.16e-05</td> <td> 2.57e-05</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>less_100m</th>                     <td>   -0.0057</td> <td>    0.003</td> <td>   -1.886</td> <td> 0.059</td> <td>   -0.012</td> <td>    0.000</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>less_500m</th>                     <td>   -0.0009</td> <td>    0.001</td> <td>   -1.163</td> <td> 0.245</td> <td>   -0.002</td> <td>    0.001</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>less_1km</th>                      <td>    0.0002</td> <td>    0.000</td> <td>    0.643</td> <td> 0.521</td> <td>   -0.000</td> <td>    0.001</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>less_5km</th>                      <td>   -0.0001</td> <td> 5.73e-05</td> <td>   -2.305</td> <td> 0.021</td> <td>   -0.000</td> <td>-1.97e-05</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>less_10km</th>                     <td> 4.844e-05</td> <td> 3.84e-05</td> <td>    1.263</td> <td> 0.207</td> <td>-2.68e-05</td> <td>    0.000</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>less_50km</th>                     <td>-8.181e-05</td> <td> 2.55e-05</td> <td>   -3.206</td> <td> 0.001</td> <td>   -0.000</td> <td>-3.18e-05</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>class_0</th>                       <td>   -0.0005</td> <td>    0.001</td> <td>   -0.829</td> <td> 0.407</td> <td>   -0.002</td> <td>    0.001</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>class_1</th>                       <td>   -0.0086</td> <td>    0.010</td> <td>   -0.835</td> <td> 0.404</td> <td>   -0.029</td> <td>    0.012</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>class_10</th>                      <td>   -0.0563</td> <td>    0.048</td> <td>   -1.165</td> <td> 0.244</td> <td>   -0.151</td> <td>    0.038</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>class_11</th>                      <td>    0.0516</td> <td>    0.036</td> <td>    1.445</td> <td> 0.148</td> <td>   -0.018</td> <td>    0.122</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>class_12</th>                      <td>   -0.0685</td> <td>    0.045</td> <td>   -1.508</td> <td> 0.132</td> <td>   -0.157</td> <td>    0.021</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>class_13</th>                      <td>    0.0071</td> <td>    0.012</td> <td>    0.585</td> <td> 0.558</td> <td>   -0.017</td> <td>    0.031</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>class_14</th>                      <td>   -0.0186</td> <td>    0.048</td> <td>   -0.389</td> <td> 0.697</td> <td>   -0.112</td> <td>    0.075</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>class_15</th>                      <td>    0.0219</td> <td>    0.033</td> <td>    0.655</td> <td> 0.513</td> <td>   -0.044</td> <td>    0.087</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>class_16</th>                      <td>    0.0165</td> <td>    0.019</td> <td>    0.855</td> <td> 0.392</td> <td>   -0.021</td> <td>    0.054</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>class_17</th>                      <td>-1.139e-16</td> <td> 2.97e-16</td> <td>   -0.383</td> <td> 0.702</td> <td>-6.97e-16</td> <td> 4.69e-16</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>class_2</th>                       <td>    0.0105</td> <td>    0.004</td> <td>    2.645</td> <td> 0.008</td> <td>    0.003</td> <td>    0.018</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>class_20</th>                      <td>   -0.0270</td> <td>    0.283</td> <td>   -0.095</td> <td> 0.924</td> <td>   -0.582</td> <td>    0.528</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>class_22</th>                      <td>-1.808e-16</td> <td> 6.88e-16</td> <td>   -0.263</td> <td> 0.793</td> <td>-1.53e-15</td> <td> 1.17e-15</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>class_23</th>                      <td>    0.0565</td> <td>    0.102</td> <td>    0.555</td> <td> 0.579</td> <td>   -0.143</td> <td>    0.256</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>class_24</th>                      <td>   -0.0018</td> <td>    0.021</td> <td>   -0.085</td> <td> 0.932</td> <td>   -0.043</td> <td>    0.040</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>class_25</th>                      <td>    0.0081</td> <td>    0.008</td> <td>    1.077</td> <td> 0.281</td> <td>   -0.007</td> <td>    0.023</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>class_26</th>                      <td>    0.0091</td> <td>    0.016</td> <td>    0.582</td> <td> 0.561</td> <td>   -0.022</td> <td>    0.040</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>class_27</th>                      <td>   -0.0033</td> <td>    0.028</td> <td>   -0.116</td> <td> 0.908</td> <td>   -0.058</td> <td>    0.052</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>class_28</th>                      <td>   -0.0393</td> <td>    0.019</td> <td>   -2.042</td> <td> 0.041</td> <td>   -0.077</td> <td>   -0.002</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>class_29</th>                      <td>    0.0294</td> <td>    0.077</td> <td>    0.382</td> <td> 0.702</td> <td>   -0.121</td> <td>    0.180</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>class_3</th>                       <td>    0.0013</td> <td>    0.017</td> <td>    0.079</td> <td> 0.937</td> <td>   -0.031</td> <td>    0.034</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>class_31</th>                      <td>-8.225e-17</td> <td> 1.99e-16</td> <td>   -0.413</td> <td> 0.679</td> <td>-4.72e-16</td> <td> 3.08e-16</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>class_32</th>                      <td>   -0.0220</td> <td>    0.041</td> <td>   -0.532</td> <td> 0.595</td> <td>   -0.103</td> <td>    0.059</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>class_33</th>                      <td>   -0.0334</td> <td>    0.087</td> <td>   -0.385</td> <td> 0.700</td> <td>   -0.203</td> <td>    0.137</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>class_34</th>                      <td>    0.1047</td> <td>    0.117</td> <td>    0.895</td> <td> 0.371</td> <td>   -0.125</td> <td>    0.334</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>class_35</th>                      <td>-4.556e-18</td> <td> 1.29e-16</td> <td>   -0.035</td> <td> 0.972</td> <td>-2.58e-16</td> <td> 2.49e-16</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>class_36</th>                      <td>    0.0291</td> <td>    0.069</td> <td>    0.419</td> <td> 0.675</td> <td>   -0.107</td> <td>    0.165</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>class_37</th>                      <td>    0.0655</td> <td>    0.137</td> <td>    0.479</td> <td> 0.632</td> <td>   -0.202</td> <td>    0.333</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>class_38</th>                      <td> 1.176e-17</td> <td> 5.07e-17</td> <td>    0.232</td> <td> 0.817</td> <td>-8.77e-17</td> <td> 1.11e-16</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>class_39</th>                      <td>    0.0041</td> <td>    0.001</td> <td>    2.776</td> <td> 0.006</td> <td>    0.001</td> <td>    0.007</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>class_4</th>                       <td>    0.0378</td> <td>    0.138</td> <td>    0.273</td> <td> 0.785</td> <td>   -0.233</td> <td>    0.309</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>class_40</th>                      <td>   -0.0050</td> <td>    0.004</td> <td>   -1.231</td> <td> 0.218</td> <td>   -0.013</td> <td>    0.003</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>class_41</th>                      <td>    0.0019</td> <td>    0.002</td> <td>    1.232</td> <td> 0.218</td> <td>   -0.001</td> <td>    0.005</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>class_42</th>                      <td>    0.0133</td> <td>    0.008</td> <td>    1.643</td> <td> 0.100</td> <td>   -0.003</td> <td>    0.029</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>class_43</th>                      <td>    0.0094</td> <td>    0.012</td> <td>    0.814</td> <td> 0.416</td> <td>   -0.013</td> <td>    0.032</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>class_44</th>                      <td>    0.0003</td> <td>    0.007</td> <td>    0.040</td> <td> 0.968</td> <td>   -0.014</td> <td>    0.014</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>class_45</th>                      <td>   -0.0015</td> <td>    0.003</td> <td>   -0.559</td> <td> 0.576</td> <td>   -0.007</td> <td>    0.004</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>class_46</th>                      <td>    0.0085</td> <td>    0.011</td> <td>    0.740</td> <td> 0.459</td> <td>   -0.014</td> <td>    0.031</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>class_47</th>                      <td>    0.0078</td> <td>    0.018</td> <td>    0.428</td> <td> 0.669</td> <td>   -0.028</td> <td>    0.044</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>class_48</th>                      <td>    0.0002</td> <td>    0.004</td> <td>    0.046</td> <td> 0.963</td> <td>   -0.008</td> <td>    0.008</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>class_49</th>                      <td>   -0.0050</td> <td>    0.012</td> <td>   -0.401</td> <td> 0.689</td> <td>   -0.029</td> <td>    0.019</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>class_5</th>                       <td>    0.1239</td> <td>    0.075</td> <td>    1.642</td> <td> 0.101</td> <td>   -0.024</td> <td>    0.272</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>class_50</th>                      <td>    0.0121</td> <td>    0.012</td> <td>    0.970</td> <td> 0.332</td> <td>   -0.012</td> <td>    0.037</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>class_51</th>                      <td>   -0.0006</td> <td>    0.009</td> <td>   -0.063</td> <td> 0.950</td> <td>   -0.019</td> <td>    0.018</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>class_52</th>                      <td>   -0.0017</td> <td>    0.010</td> <td>   -0.180</td> <td> 0.857</td> <td>   -0.020</td> <td>    0.017</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>class_53</th>                      <td>    0.0039</td> <td>    0.008</td> <td>    0.457</td> <td> 0.648</td> <td>   -0.013</td> <td>    0.020</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>class_54</th>                      <td>    0.0046</td> <td>    0.002</td> <td>    2.247</td> <td> 0.025</td> <td>    0.001</td> <td>    0.009</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>class_55</th>                      <td>    0.0013</td> <td>    0.003</td> <td>    0.403</td> <td> 0.687</td> <td>   -0.005</td> <td>    0.008</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>class_56</th>                      <td> 2.307e-05</td> <td>    0.001</td> <td>    0.030</td> <td> 0.976</td> <td>   -0.002</td> <td>    0.002</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>class_57</th>                      <td>    0.0015</td> <td>    0.009</td> <td>    0.166</td> <td> 0.868</td> <td>   -0.017</td> <td>    0.020</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>class_58</th>                      <td>    0.0018</td> <td>    0.002</td> <td>    0.850</td> <td> 0.396</td> <td>   -0.002</td> <td>    0.006</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>class_59</th>                      <td>   -0.0371</td> <td>    0.051</td> <td>   -0.729</td> <td> 0.466</td> <td>   -0.137</td> <td>    0.063</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>class_6</th>                       <td>   -0.0047</td> <td>    0.121</td> <td>   -0.039</td> <td> 0.969</td> <td>   -0.241</td> <td>    0.232</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>class_60</th>                      <td>    0.0004</td> <td>    0.003</td> <td>    0.135</td> <td> 0.892</td> <td>   -0.006</td> <td>    0.007</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>class_61</th>                      <td>   -0.0430</td> <td>    0.036</td> <td>   -1.197</td> <td> 0.232</td> <td>   -0.113</td> <td>    0.027</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>class_62</th>                      <td>    0.0047</td> <td>    0.005</td> <td>    0.911</td> <td> 0.362</td> <td>   -0.005</td> <td>    0.015</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>class_63</th>                      <td>    0.0129</td> <td>    0.011</td> <td>    1.155</td> <td> 0.248</td> <td>   -0.009</td> <td>    0.035</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>class_64</th>                      <td>   -0.1397</td> <td>    0.098</td> <td>   -1.428</td> <td> 0.153</td> <td>   -0.331</td> <td>    0.052</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>class_65</th>                      <td>   -0.0148</td> <td>    0.056</td> <td>   -0.264</td> <td> 0.791</td> <td>   -0.124</td> <td>    0.095</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>class_66</th>                      <td>    0.1308</td> <td>    0.094</td> <td>    1.390</td> <td> 0.164</td> <td>   -0.054</td> <td>    0.315</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>class_67</th>                      <td>    0.0134</td> <td>    0.013</td> <td>    1.012</td> <td> 0.312</td> <td>   -0.013</td> <td>    0.039</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>class_68</th>                      <td>    0.0037</td> <td>    0.017</td> <td>    0.216</td> <td> 0.829</td> <td>   -0.030</td> <td>    0.038</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>class_69</th>                      <td>    0.0025</td> <td>    0.018</td> <td>    0.139</td> <td> 0.890</td> <td>   -0.032</td> <td>    0.037</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>class_7</th>                       <td>   -0.0031</td> <td>    0.033</td> <td>   -0.093</td> <td> 0.926</td> <td>   -0.069</td> <td>    0.062</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>class_70</th>                      <td>         0</td> <td>        0</td> <td>      nan</td> <td>   nan</td> <td>        0</td> <td>        0</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>class_71</th>                      <td>    0.0039</td> <td>    0.025</td> <td>    0.154</td> <td> 0.877</td> <td>   -0.045</td> <td>    0.053</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>class_72</th>                      <td>   -0.0023</td> <td>    0.010</td> <td>   -0.229</td> <td> 0.819</td> <td>   -0.022</td> <td>    0.017</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>class_73</th>                      <td>   -0.0004</td> <td>    0.011</td> <td>   -0.033</td> <td> 0.973</td> <td>   -0.022</td> <td>    0.021</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>class_74</th>                      <td>   -0.0015</td> <td>    0.009</td> <td>   -0.155</td> <td> 0.877</td> <td>   -0.020</td> <td>    0.017</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>class_75</th>                      <td>    0.0028</td> <td>    0.006</td> <td>    0.499</td> <td> 0.617</td> <td>   -0.008</td> <td>    0.014</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>class_76</th>                      <td>    0.0112</td> <td>    0.083</td> <td>    0.135</td> <td> 0.893</td> <td>   -0.152</td> <td>    0.174</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>class_77</th>                      <td>    0.0268</td> <td>    0.019</td> <td>    1.435</td> <td> 0.151</td> <td>   -0.010</td> <td>    0.063</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>class_79</th>                      <td>   -0.0145</td> <td>    0.057</td> <td>   -0.255</td> <td> 0.799</td> <td>   -0.126</td> <td>    0.097</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>class_8</th>                       <td>   -0.1196</td> <td>    0.279</td> <td>   -0.429</td> <td> 0.668</td> <td>   -0.666</td> <td>    0.427</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>class_9</th>                       <td>   -0.0071</td> <td>    0.012</td> <td>   -0.616</td> <td> 0.538</td> <td>   -0.030</td> <td>    0.016</td>\n",
       "</tr>\n",
       "</table>\n",
       "<table class=\"simpletable\">\n",
       "<tr>\n",
       "  <th>Omnibus:</th>       <td>709.003</td> <th>  Durbin-Watson:     </th> <td>   1.930</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Prob(Omnibus):</th> <td> 0.000</td>  <th>  Jarque-Bera (JB):  </th> <td>2932.914</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Skew:</th>          <td>-0.503</td>  <th>  Prob(JB):          </th> <td>    0.00</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Kurtosis:</th>      <td> 6.203</td>  <th>  Cond. No.          </th> <td>8.32e+19</td>\n",
       "</tr>\n",
       "</table><br/><br/>Notes:<br/>[1] Standard Errors assume that the covariance matrix of the errors is correctly specified.<br/>[2] The smallest eigenvalue is 6.4e-20. This might indicate that there are<br/>strong multicollinearity problems or that the design matrix is singular."
      ],
      "text/plain": [
       "<class 'statsmodels.iolib.summary.Summary'>\n",
       "\"\"\"\n",
       "                            OLS Regression Results                            \n",
       "==============================================================================\n",
       "Dep. Variable:        weighted_rating   R-squared:                       0.761\n",
       "Model:                            OLS   Adj. R-squared:                  0.756\n",
       "Method:                 Least Squares   F-statistic:                     149.4\n",
       "Date:                Sat, 21 May 2022   Prob (F-statistic):               0.00\n",
       "Time:                        10:54:14   Log-Likelihood:                -651.33\n",
       "No. Observations:                6244   AIC:                             1565.\n",
       "Df Residuals:                    6113   BIC:                             2448.\n",
       "Df Model:                         130                                         \n",
       "Covariance Type:            nonrobust                                         \n",
       "=================================================================================================\n",
       "                                    coef    std err          t      P>|t|      [0.025      0.975]\n",
       "-------------------------------------------------------------------------------------------------\n",
       "const                         -5.801e-09   1.37e-07     -0.042      0.966   -2.74e-07    2.63e-07\n",
       "stars                             0.4086      0.008     52.292      0.000       0.393       0.424\n",
       "rate_user_num                    -0.0034      0.001     -2.596      0.009      -0.006      -0.001\n",
       "state                          2.551e-07   1.38e-07      1.843      0.065   -1.62e-08    5.26e-07\n",
       "latitude                          0.0162      0.036      0.456      0.648      -0.053       0.086\n",
       "longitude                         0.0566      0.029      1.963      0.050    6.76e-05       0.113\n",
       "review_count                      0.0032      0.001      2.409      0.016       0.001       0.006\n",
       "price_level                       0.0094      0.008      1.198      0.231      -0.006       0.025\n",
       "HasTV                             0.0374      0.006      6.681      0.000       0.026       0.048\n",
       "Caters                           -0.0072      0.005     -1.524      0.128      -0.017       0.002\n",
       "OutdoorSeating                   -0.0216      0.006     -3.846      0.000      -0.033      -0.011\n",
       "WheelchairAccessible              0.0051      0.008      0.630      0.529      -0.011       0.021\n",
       "BusinessParking                   0.0060      0.008      0.718      0.473      -0.010       0.022\n",
       "RestaurantsDelivery               0.0107      0.006      1.863      0.063      -0.001       0.022\n",
       "BikeParking                       0.0142      0.007      2.152      0.031       0.001       0.027\n",
       "WiFi                             -0.0014      0.007     -0.193      0.847      -0.016       0.013\n",
       "Alcohol                          -0.0014      0.007     -0.193      0.847      -0.016       0.013\n",
       "RestaurantsTakeOut               -0.0060      0.010     -0.580      0.562      -0.026       0.014\n",
       "BusinessAcceptsCreditCards       -0.0014      0.013     -0.109      0.914      -0.027       0.024\n",
       "open_days                         0.0149      0.003      5.756      0.000       0.010       0.020\n",
       "open_hours                       -0.0010      0.000     -9.137      0.000      -0.001      -0.001\n",
       "rating                            0.1685      0.004     41.189      0.000       0.160       0.176\n",
       "num_rating                     4.993e-05   4.44e-06     11.245      0.000    4.12e-05    5.86e-05\n",
       "photo_drink                       0.0123      0.004      2.741      0.006       0.003       0.021\n",
       "photo_food                        0.0011      0.004      0.290      0.772      -0.006       0.008\n",
       "photo_inside                     -0.0009      0.004     -0.242      0.809      -0.008       0.007\n",
       "photo_menu                       -0.0127      0.016     -0.786      0.432      -0.044       0.019\n",
       "photo_outside                    -0.0027      0.006     -0.444      0.657      -0.015       0.009\n",
       "photo_total                      -0.0029      0.004     -0.741      0.459      -0.011       0.005\n",
       "user_avg_stars                   -0.0479      0.018     -2.710      0.007      -0.083      -0.013\n",
       "user_avg_review_count            -0.0002   5.03e-05     -4.167      0.000      -0.000      -0.000\n",
       "user_avg_useful                1.285e-05   4.05e-05      0.318      0.751   -6.65e-05    9.22e-05\n",
       "user_avg_funny                 1.257e-05   2.77e-05      0.453      0.650   -4.18e-05    6.69e-05\n",
       "user_avg_cool                  1.502e-05   5.19e-05      0.289      0.772   -8.67e-05       0.000\n",
       "user_avg_fans                    -0.0003      0.000     -1.073      0.284      -0.001       0.000\n",
       "user_avg_compliment_hot          -0.0004      0.000     -1.083      0.279      -0.001       0.000\n",
       "user_avg_compliment_more          0.0033      0.003      1.267      0.205      -0.002       0.008\n",
       "user_avg_compliment_profile      -0.0047      0.002     -1.970      0.049      -0.009    -2.4e-05\n",
       "user_avg_compliment_cute         -0.0022      0.003     -0.801      0.423      -0.008       0.003\n",
       "user_avg_compliment_list          0.0096      0.004      2.439      0.015       0.002       0.017\n",
       "user_avg_compliment_note         -0.0007      0.000     -3.481      0.001      -0.001      -0.000\n",
       "user_avg_compliment_plain        -0.0005      0.000     -2.638      0.008      -0.001      -0.000\n",
       "user_avg_compliment_cool         -0.0009      0.000     -3.561      0.000      -0.001      -0.000\n",
       "user_avg_compliment_funny        -0.0009      0.000     -3.561      0.000      -0.001      -0.000\n",
       "user_avg_compliment_writer       -0.0009      0.000     -2.167      0.030      -0.002   -8.56e-05\n",
       "user_avg_compliment_photos       -0.0009      0.000     -3.757      0.000      -0.001      -0.000\n",
       "user_yelp_years               -3.192e-10   9.43e-11     -3.386      0.001   -5.04e-10   -1.34e-10\n",
       "user_avg_total_compliment         0.0007      0.000      3.552      0.000       0.000       0.001\n",
       "state_state                    2.548e-07   1.38e-07      1.841      0.066   -1.64e-08    5.26e-07\n",
       "abbrev                         2.548e-07   1.38e-07      1.841      0.066   -1.64e-08    5.26e-07\n",
       "code                           2.548e-07   1.38e-07      1.841      0.066   -1.64e-08    5.26e-07\n",
       "full_state                     2.548e-07   1.38e-07      1.841      0.066   -1.64e-08    5.26e-07\n",
       "Total:_Estimate               -2.958e-06   1.73e-06     -1.711      0.087   -6.35e-06    4.32e-07\n",
       "Less than $20,000_Estimate    -1.509e-05   7.26e-06     -2.077      0.038   -2.93e-05    -8.5e-07\n",
       "$20,000 to $39,999_Estimate    4.604e-06   4.44e-06      1.037      0.300    -4.1e-06    1.33e-05\n",
       "$40,000 to $59,999_Estimate   -3.731e-06   6.27e-06     -0.595      0.552    -1.6e-05    8.55e-06\n",
       "$60,000 to $99,999_Estimate     1.48e-05   9.46e-06      1.565      0.118   -3.74e-06    3.33e-05\n",
       "$100,000 to $149,999_Estimate -2.325e-05   1.16e-05     -2.001      0.045    -4.6e-05   -4.68e-07\n",
       "$150,000 to $199,999_Estimate  2.616e-05   1.17e-05      2.231      0.026    3.17e-06    4.91e-05\n",
       "$200,000 or more_Estimate     -6.452e-06   3.24e-06     -1.989      0.047   -1.28e-05   -9.25e-08\n",
       "PAYANN                         1.031e-06   7.26e-07      1.421      0.155   -3.92e-07    2.45e-06\n",
       "PCHDAPR                       -7.886e-05   5.29e-05     -1.492      0.136      -0.000    2.48e-05\n",
       "PCHADVT                           0.0002      0.000      1.782      0.075   -2.29e-05       0.000\n",
       "DENSITY_2021                  -1.667e-05   1.45e-05     -1.148      0.251   -4.51e-05    1.18e-05\n",
       "POP_2021                       3.473e-06   1.82e-06      1.903      0.057   -1.04e-07    7.05e-06\n",
       "Total:_max                     5.923e-05   3.27e-05      1.812      0.070   -4.85e-06       0.000\n",
       "Less than $20,000_max         -4.606e-05   3.94e-05     -1.169      0.242      -0.000    3.12e-05\n",
       "$20,000 to $39,999_max         6.337e-05   3.45e-05      1.839      0.066   -4.19e-06       0.000\n",
       "$40,000 to $59,999_max            0.0001   7.82e-05      1.795      0.073   -1.29e-05       0.000\n",
       "$60,000 to $99,999_max            0.0002      0.000      1.737      0.082   -2.36e-05       0.000\n",
       "$100,000 to $149,999_max       5.427e-05   3.77e-05      1.440      0.150   -1.96e-05       0.000\n",
       "$150,000 to $199,999_max       4.007e-05    1.5e-05      2.671      0.008    1.07e-05    6.95e-05\n",
       "$200,000 or more_max          -4.933e-06   1.78e-05     -0.277      0.782   -3.99e-05       3e-05\n",
       "Total:_min                    -6.514e-05   3.61e-05     -1.803      0.071      -0.000    5.69e-06\n",
       "Less than $20,000_min          1.588e-05   2.92e-05      0.545      0.586   -4.13e-05     7.3e-05\n",
       "$20,000 to $39,999_min        -5.416e-05   2.78e-05     -1.945      0.052      -0.000    4.29e-07\n",
       "$40,000 to $59,999_min           -0.0001   8.07e-05     -1.833      0.067      -0.000    1.03e-05\n",
       "$60,000 to $99,999_min           -0.0002   8.97e-05     -1.719      0.086      -0.000    2.17e-05\n",
       "$100,000 to $149,999_min         -0.0001   5.83e-05     -1.729      0.084      -0.000    1.35e-05\n",
       "$150,000 to $199,999_min       1.225e-05   1.31e-05      0.938      0.348   -1.34e-05    3.79e-05\n",
       "$200,000 or more_min          -7.971e-06   1.72e-05     -0.464      0.642   -4.16e-05    2.57e-05\n",
       "less_100m                        -0.0057      0.003     -1.886      0.059      -0.012       0.000\n",
       "less_500m                        -0.0009      0.001     -1.163      0.245      -0.002       0.001\n",
       "less_1km                          0.0002      0.000      0.643      0.521      -0.000       0.001\n",
       "less_5km                         -0.0001   5.73e-05     -2.305      0.021      -0.000   -1.97e-05\n",
       "less_10km                      4.844e-05   3.84e-05      1.263      0.207   -2.68e-05       0.000\n",
       "less_50km                     -8.181e-05   2.55e-05     -3.206      0.001      -0.000   -3.18e-05\n",
       "class_0                          -0.0005      0.001     -0.829      0.407      -0.002       0.001\n",
       "class_1                          -0.0086      0.010     -0.835      0.404      -0.029       0.012\n",
       "class_10                         -0.0563      0.048     -1.165      0.244      -0.151       0.038\n",
       "class_11                          0.0516      0.036      1.445      0.148      -0.018       0.122\n",
       "class_12                         -0.0685      0.045     -1.508      0.132      -0.157       0.021\n",
       "class_13                          0.0071      0.012      0.585      0.558      -0.017       0.031\n",
       "class_14                         -0.0186      0.048     -0.389      0.697      -0.112       0.075\n",
       "class_15                          0.0219      0.033      0.655      0.513      -0.044       0.087\n",
       "class_16                          0.0165      0.019      0.855      0.392      -0.021       0.054\n",
       "class_17                      -1.139e-16   2.97e-16     -0.383      0.702   -6.97e-16    4.69e-16\n",
       "class_2                           0.0105      0.004      2.645      0.008       0.003       0.018\n",
       "class_20                         -0.0270      0.283     -0.095      0.924      -0.582       0.528\n",
       "class_22                      -1.808e-16   6.88e-16     -0.263      0.793   -1.53e-15    1.17e-15\n",
       "class_23                          0.0565      0.102      0.555      0.579      -0.143       0.256\n",
       "class_24                         -0.0018      0.021     -0.085      0.932      -0.043       0.040\n",
       "class_25                          0.0081      0.008      1.077      0.281      -0.007       0.023\n",
       "class_26                          0.0091      0.016      0.582      0.561      -0.022       0.040\n",
       "class_27                         -0.0033      0.028     -0.116      0.908      -0.058       0.052\n",
       "class_28                         -0.0393      0.019     -2.042      0.041      -0.077      -0.002\n",
       "class_29                          0.0294      0.077      0.382      0.702      -0.121       0.180\n",
       "class_3                           0.0013      0.017      0.079      0.937      -0.031       0.034\n",
       "class_31                      -8.225e-17   1.99e-16     -0.413      0.679   -4.72e-16    3.08e-16\n",
       "class_32                         -0.0220      0.041     -0.532      0.595      -0.103       0.059\n",
       "class_33                         -0.0334      0.087     -0.385      0.700      -0.203       0.137\n",
       "class_34                          0.1047      0.117      0.895      0.371      -0.125       0.334\n",
       "class_35                      -4.556e-18   1.29e-16     -0.035      0.972   -2.58e-16    2.49e-16\n",
       "class_36                          0.0291      0.069      0.419      0.675      -0.107       0.165\n",
       "class_37                          0.0655      0.137      0.479      0.632      -0.202       0.333\n",
       "class_38                       1.176e-17   5.07e-17      0.232      0.817   -8.77e-17    1.11e-16\n",
       "class_39                          0.0041      0.001      2.776      0.006       0.001       0.007\n",
       "class_4                           0.0378      0.138      0.273      0.785      -0.233       0.309\n",
       "class_40                         -0.0050      0.004     -1.231      0.218      -0.013       0.003\n",
       "class_41                          0.0019      0.002      1.232      0.218      -0.001       0.005\n",
       "class_42                          0.0133      0.008      1.643      0.100      -0.003       0.029\n",
       "class_43                          0.0094      0.012      0.814      0.416      -0.013       0.032\n",
       "class_44                          0.0003      0.007      0.040      0.968      -0.014       0.014\n",
       "class_45                         -0.0015      0.003     -0.559      0.576      -0.007       0.004\n",
       "class_46                          0.0085      0.011      0.740      0.459      -0.014       0.031\n",
       "class_47                          0.0078      0.018      0.428      0.669      -0.028       0.044\n",
       "class_48                          0.0002      0.004      0.046      0.963      -0.008       0.008\n",
       "class_49                         -0.0050      0.012     -0.401      0.689      -0.029       0.019\n",
       "class_5                           0.1239      0.075      1.642      0.101      -0.024       0.272\n",
       "class_50                          0.0121      0.012      0.970      0.332      -0.012       0.037\n",
       "class_51                         -0.0006      0.009     -0.063      0.950      -0.019       0.018\n",
       "class_52                         -0.0017      0.010     -0.180      0.857      -0.020       0.017\n",
       "class_53                          0.0039      0.008      0.457      0.648      -0.013       0.020\n",
       "class_54                          0.0046      0.002      2.247      0.025       0.001       0.009\n",
       "class_55                          0.0013      0.003      0.403      0.687      -0.005       0.008\n",
       "class_56                       2.307e-05      0.001      0.030      0.976      -0.002       0.002\n",
       "class_57                          0.0015      0.009      0.166      0.868      -0.017       0.020\n",
       "class_58                          0.0018      0.002      0.850      0.396      -0.002       0.006\n",
       "class_59                         -0.0371      0.051     -0.729      0.466      -0.137       0.063\n",
       "class_6                          -0.0047      0.121     -0.039      0.969      -0.241       0.232\n",
       "class_60                          0.0004      0.003      0.135      0.892      -0.006       0.007\n",
       "class_61                         -0.0430      0.036     -1.197      0.232      -0.113       0.027\n",
       "class_62                          0.0047      0.005      0.911      0.362      -0.005       0.015\n",
       "class_63                          0.0129      0.011      1.155      0.248      -0.009       0.035\n",
       "class_64                         -0.1397      0.098     -1.428      0.153      -0.331       0.052\n",
       "class_65                         -0.0148      0.056     -0.264      0.791      -0.124       0.095\n",
       "class_66                          0.1308      0.094      1.390      0.164      -0.054       0.315\n",
       "class_67                          0.0134      0.013      1.012      0.312      -0.013       0.039\n",
       "class_68                          0.0037      0.017      0.216      0.829      -0.030       0.038\n",
       "class_69                          0.0025      0.018      0.139      0.890      -0.032       0.037\n",
       "class_7                          -0.0031      0.033     -0.093      0.926      -0.069       0.062\n",
       "class_70                               0          0        nan        nan           0           0\n",
       "class_71                          0.0039      0.025      0.154      0.877      -0.045       0.053\n",
       "class_72                         -0.0023      0.010     -0.229      0.819      -0.022       0.017\n",
       "class_73                         -0.0004      0.011     -0.033      0.973      -0.022       0.021\n",
       "class_74                         -0.0015      0.009     -0.155      0.877      -0.020       0.017\n",
       "class_75                          0.0028      0.006      0.499      0.617      -0.008       0.014\n",
       "class_76                          0.0112      0.083      0.135      0.893      -0.152       0.174\n",
       "class_77                          0.0268      0.019      1.435      0.151      -0.010       0.063\n",
       "class_79                         -0.0145      0.057     -0.255      0.799      -0.126       0.097\n",
       "class_8                          -0.1196      0.279     -0.429      0.668      -0.666       0.427\n",
       "class_9                          -0.0071      0.012     -0.616      0.538      -0.030       0.016\n",
       "==============================================================================\n",
       "Omnibus:                      709.003   Durbin-Watson:                   1.930\n",
       "Prob(Omnibus):                  0.000   Jarque-Bera (JB):             2932.914\n",
       "Skew:                          -0.503   Prob(JB):                         0.00\n",
       "Kurtosis:                       6.203   Cond. No.                     8.32e+19\n",
       "==============================================================================\n",
       "\n",
       "Notes:\n",
       "[1] Standard Errors assume that the covariance matrix of the errors is correctly specified.\n",
       "[2] The smallest eigenvalue is 6.4e-20. This might indicate that there are\n",
       "strong multicollinearity problems or that the design matrix is singular.\n",
       "\"\"\""
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X['user_yelp_years'] = X['user_yelp_years'] / np.timedelta64(1, 's')\n",
    "for i in X.columns:\n",
    "    if X[i].dtype == np.object:\n",
    "        X[i] = pd.factorize(X[i])[0]\n",
    "#print(X['state_state'])\n",
    "X.replace([np.inf, -np.inf], 0, inplace=True)\n",
    "X.replace(np.nan, 0, inplace=True)\n",
    "## fit a OLS model with intercept\n",
    "X = sm.add_constant(X)\n",
    "est = sm.OLS(y,X,missing='drop').fit()\n",
    "est.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## --------------------------------------------------------------------------------------------------------"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "D:\\Anaconda\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:529: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 566.5685637339349, tolerance: 0.140736252539041\n",
      "  model = cd_fast.enet_coordinate_descent(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "R squared training set 22.44\n",
      "R squared test set 9.89\n",
      "Mean MAE: 0.381 (0.027)\n"
     ]
    }
   ],
   "source": [
    "# lasso - alpha = 1\n",
    "from numpy import mean\n",
    "from numpy import std\n",
    "from numpy import absolute\n",
    "from pandas import read_csv\n",
    "from sklearn.model_selection import cross_val_score\n",
    "from sklearn.model_selection import RepeatedKFold\n",
    "from sklearn.linear_model import Lasso\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "## by sklearn package\n",
    "from sklearn.model_selection import train_test_split\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.25, random_state=10)\n",
    "\n",
    "model = Lasso(alpha=1.0)\n",
    "# define model evaluation method\n",
    "cv = RepeatedKFold(n_splits=10, n_repeats=3, random_state=1)\n",
    "model.fit(X_train, y_train)\n",
    "#print(model.coef_)\n",
    "# evaluate model\n",
    "scores = cross_val_score(model, X_test, y_test, scoring='neg_mean_absolute_error', cv=cv, n_jobs=-1)\n",
    "# force scores to be positive\n",
    "scores = absolute(scores)\n",
    "print('R squared training set', round(model.score(X_train, y_train)*100, 2))\n",
    "print('R squared test set', round(model.score(X_test, y_test)*100, 2))\n",
    "print('Mean MAE: %.3f (%.3f)' % (mean(scores), std(scores)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "R squared training set 0.0\n",
      "R squared test set -0.02\n",
      "Mean MAE: 0.439 (0.025)\n"
     ]
    }
   ],
   "source": [
    "# lasso - with alpha = 1 & x scaled\n",
    "from numpy import mean\n",
    "from numpy import std\n",
    "from numpy import absolute\n",
    "from pandas import read_csv\n",
    "from sklearn.model_selection import cross_val_score\n",
    "from sklearn.model_selection import RepeatedKFold\n",
    "from sklearn.linear_model import Lasso\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "## by sklearn package\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "sc = StandardScaler()\n",
    "X_scaled = sc.fit_transform(X)\n",
    "X_scaled = pd.DataFrame(data = X_scaled, columns = X.columns)\n",
    "X_train, X_test, y_train, y_test = train_test_split(X_scaled, y, test_size=0.25, random_state=10)\n",
    "\n",
    "model = Lasso(alpha=1.0)\n",
    "# define model evaluation method\n",
    "cv = RepeatedKFold(n_splits=10, n_repeats=3, random_state=1)\n",
    "model.fit(X_train, y_train)\n",
    "#print(model.coef_)\n",
    "# evaluate model\n",
    "scores = cross_val_score(model, X_test, y_test, scoring='neg_mean_absolute_error', cv=cv, n_jobs=-1)\n",
    "# force scores to be positive\n",
    "scores = absolute(scores)\n",
    "print('R squared training set', round(model.score(X_train, y_train)*100, 2))\n",
    "print('R squared test set', round(model.score(X_test, y_test)*100, 2))\n",
    "print('Mean MAE: %.3f (%.3f)' % (mean(scores), std(scores)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "-------------------"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "D:\\Anaconda\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:529: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 392.98496273448615, tolerance: 0.140736252539041\n",
      "  model = cd_fast.enet_coordinate_descent(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "R squared training set 68.11\n",
      "R squared test set 66.85\n",
      "Mean MAE: 0.227 (0.017)\n"
     ]
    }
   ],
   "source": [
    "# lasso with alpha = 0.1 \n",
    "from sklearn.model_selection import train_test_split\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.25, random_state=10)\n",
    "\n",
    "from sklearn import linear_model\n",
    "clf = linear_model.Lasso(alpha=0.1)\n",
    "clf.fit(X_train,y_train)\n",
    "\n",
    "print('R squared training set', round(clf.score(X_train, y_train)*100, 2))\n",
    "print('R squared test set', round(clf.score(X_test, y_test)*100, 2))\n",
    "\n",
    "scores = cross_val_score(clf, X_test, y_test, scoring='neg_mean_absolute_error', cv=cv, n_jobs=-1)\n",
    "# force scores to be positive\n",
    "scores = absolute(scores)\n",
    "print('Mean MAE: %.3f (%.3f)' % (mean(scores), std(scores)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "R squared training set 68.08\n",
      "R squared test set 68.49\n",
      "Mean MAE: 0.222 (0.016)\n"
     ]
    }
   ],
   "source": [
    "# lasso with alpha = 0.1 & x scaled\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "sc = StandardScaler()\n",
    "X_scaled = sc.fit_transform(X)\n",
    "X_scaled = pd.DataFrame(data = X_scaled, columns = X.columns)\n",
    "X_train, X_test, y_train, y_test = train_test_split(X_scaled, y, test_size=0.25, random_state=10)\n",
    "\n",
    "clf = linear_model.Lasso(alpha=0.1)\n",
    "clf.fit(X_train,y_train)\n",
    "\n",
    "print('R squared training set', round(clf.score(X_train, y_train)*100, 2))\n",
    "print('R squared test set', round(clf.score(X_test, y_test)*100, 2))\n",
    "\n",
    "scores = cross_val_score(clf, X_test, y_test, scoring='neg_mean_absolute_error', cv=cv, n_jobs=-1)\n",
    "# force scores to be positive\n",
    "scores = absolute(scores)\n",
    "print('Mean MAE: %.3f (%.3f)' % (mean(scores), std(scores)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE: -0.19121\n",
      "Config: {'alpha': 0.01}\n"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import KFold, RepeatedKFold, GridSearchCV, cross_validate, train_test_split\n",
    "\n",
    "cv = RepeatedKFold(n_splits=10, n_repeats=3, random_state=1) \n",
    "lasso_alphas = np.linspace(0, 0.2, 21)\n",
    "lasso = Lasso()\n",
    "grid = dict()\n",
    "grid['alpha'] = lasso_alphas \n",
    "gscv = GridSearchCV(lasso, grid, scoring='neg_mean_absolute_error',cv=cv, n_jobs=-1) \n",
    "results = gscv.fit(X_train, y_train)\n",
    "\n",
    "print('MAE: %.5f' % results.best_score_) \n",
    "print('Config: %s' % results.best_params_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "R squared training set 74.54\n",
      "R squared test set 74.97\n",
      "Mean MAE: 0.187 (0.013)\n"
     ]
    }
   ],
   "source": [
    "# lasso with alpha = 0.1 & x scaled\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "sc = StandardScaler()\n",
    "X_scaled = sc.fit_transform(X)\n",
    "X_scaled = pd.DataFrame(data = X_scaled, columns = X.columns)\n",
    "X_train, X_test, y_train, y_test = train_test_split(X_scaled, y, test_size=0.25, random_state=10)\n",
    "\n",
    "opt_model = linear_model.Lasso(alpha=0.01)\n",
    "opt_model.fit(X_train,y_train)\n",
    "\n",
    "print('R squared training set', round(opt_model.score(X_train, y_train)*100, 2))\n",
    "print('R squared test set', round(opt_model.score(X_test, y_test)*100, 2))\n",
    "\n",
    "scores = cross_val_score(opt_model, X_test, y_test, scoring='neg_mean_absolute_error', cv=cv, n_jobs=-1)\n",
    "# force scores to be positive\n",
    "scores = absolute(scores)\n",
    "print('Mean MAE: %.3f (%.3f)' % (mean(scores), std(scores)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['rate_user_num', 'state', 'Caters', 'WheelchairAccessible', 'rating', 'num_rating', 'photo_drink', 'photo_food', 'user_avg_useful', 'user_avg_total_compliment', 'DENSITY_2021', 'less_500m', 'less_1km', 'less_10km']\n"
     ]
    }
   ],
   "source": [
    "x = ['stars', \n",
    "    'rate_user_num', \n",
    "    'state', \n",
    "    'latitude',\n",
    "    'longitude', \n",
    "    'review_count', \n",
    "    'price_level', \n",
    "    'HasTV', \n",
    "    'Caters', \n",
    "    'OutdoorSeating', \n",
    "    'WheelchairAccessible', \n",
    "    'BusinessParking', \n",
    "    'RestaurantsDelivery', \n",
    "    'BikeParking', \n",
    "    'WiFi', \n",
    "    'Alcohol', \n",
    "    'RestaurantsTakeOut',\n",
    "    'BusinessAcceptsCreditCards', \n",
    "    'open_days', \n",
    "    'open_hours', \n",
    "    'rating', \n",
    "    'num_rating', \n",
    "    'photo_drink', \n",
    "    'photo_food', \n",
    "    'photo_inside', \n",
    "    'photo_menu',\n",
    "    'photo_outside', \n",
    "    'photo_total', \n",
    "    'user_avg_stars', \n",
    "    'user_avg_review_count', \n",
    "    'user_avg_useful', \n",
    "    'user_avg_funny', \n",
    "    'user_avg_cool', \n",
    "    'user_avg_fans', \n",
    "    'user_avg_compliment_hot', \n",
    "    'user_avg_compliment_more', \n",
    "    'user_avg_compliment_profile', \n",
    "    'user_avg_compliment_cute', \n",
    "    'user_avg_compliment_list', \n",
    "    'user_avg_compliment_note', \n",
    "    'user_avg_compliment_plain', \n",
    "    'user_avg_compliment_cool',\n",
    "    'user_avg_compliment_funny', \n",
    "    'user_avg_compliment_writer', \n",
    "    'user_avg_compliment_photos', \n",
    "    'user_yelp_years', \n",
    "    'user_avg_total_compliment',\n",
    "    'state_state', \n",
    "    'abbrev',\n",
    "    'code', \n",
    "    'full_state',\n",
    "    'Total:_Estimate',\n",
    "    'Less than $20,000_Estimate', \n",
    "    '$20,000 to $39,999_Estimate', \n",
    "    '$40,000 to $59,999_Estimate', \n",
    "    '$60,000 to $99,999_Estimate', \n",
    "    '$100,000 to $149,999_Estimate',\n",
    "    '$150,000 to $199,999_Estimate', \n",
    "    '$200,000 or more_Estimate', \n",
    "    'PAYANN', 'PCHDAPR', 'PCHADVT', 'DENSITY_2021', 'POP_2021', \n",
    "    'Total:_max', 'Less than $20,000_max', '$20,000 to $39,999_max', '$40,000 to $59,999_max', \n",
    "    '$60,000 to $99,999_max', '$100,000 to $149,999_max', '$150,000 to $199,999_max', '$200,000 or more_max',\n",
    "    'Total:_min', 'Less than $20,000_min', '$20,000 to $39,999_min', '$40,000 to $59,999_min', \n",
    "    '$60,000 to $99,999_min', '$100,000 to $149,999_min', '$150,000 to $199,999_min', '$200,000 or more_min', \n",
    "    'less_100m', 'less_500m', 'less_1km', 'less_5km', 'less_10km', 'less_50km', \n",
    "    'class_0', 'class_1', 'class_10', 'class_11', 'class_12', 'class_13', 'class_14', 'class_15', \n",
    "    'class_16', 'class_17', 'class_2', 'class_20', 'class_22', 'class_23', 'class_24', 'class_25', \n",
    "    'class_26', 'class_27', 'class_28', 'class_29', 'class_3', 'class_31', 'class_32', 'class_33', \n",
    "    'class_34', 'class_35', 'class_36', 'class_37', 'class_38', 'class_39', 'class_4', 'class_40', \n",
    "    'class_41', 'class_42', 'class_43', 'class_44', 'class_45', 'class_46', 'class_47', 'class_48', \n",
    "    'class_49', 'class_5', 'class_50', 'class_51', 'class_52', 'class_53', 'class_54', 'class_55', \n",
    "    'class_56', 'class_57', 'class_58', 'class_59', 'class_6', 'class_60', 'class_61', 'class_62', \n",
    "    'class_63', 'class_64', 'class_65', 'class_66', 'class_67', 'class_68', 'class_69', 'class_7', \n",
    "    'class_70', 'class_71', 'class_72', 'class_73', 'class_74', 'class_75', 'class_76', 'class_77', \n",
    "    'class_79', 'class_8', 'class_9']\n",
    "coefficient = opt_model.coef_\n",
    "idx = []\n",
    "for index,v in enumerate(coefficient):\n",
    "    if v!=0.00000000e+00 or v!=-0.00000000e+00:\n",
    "        idx.append(index)\n",
    "selected_c = []\n",
    "for i in idx:\n",
    "    selected_c.append(x[i])\n",
    "print(selected_c)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
