{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 244,
   "metadata": {},
   "outputs": [],
   "source": [
    "# https://machinelearningmastery.com/arima-for-time-series-forecasting-with-python/\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sqlalchemy import create_engine"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 245,
   "metadata": {},
   "outputs": [],
   "source": [
    "# load data\n",
    "engine_out = create_engine(r'postgresql+psycopg2://postgres:stats170@104.197.51.5')\n",
    "sql = '''SELECT * FROM yelp_data.shop_static_info;'''\n",
    "shop_static_info = pd.read_sql_query(sql,con=engine_out)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 246,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>business_id</th>\n",
       "      <th>stars</th>\n",
       "      <th>rate_user_num</th>\n",
       "      <th>state</th>\n",
       "      <th>latitude</th>\n",
       "      <th>longitude</th>\n",
       "      <th>review_count</th>\n",
       "      <th>price_level</th>\n",
       "      <th>HasTV</th>\n",
       "      <th>Caters</th>\n",
       "      <th>...</th>\n",
       "      <th>class_71</th>\n",
       "      <th>class_72</th>\n",
       "      <th>class_73</th>\n",
       "      <th>class_74</th>\n",
       "      <th>class_75</th>\n",
       "      <th>class_76</th>\n",
       "      <th>class_77</th>\n",
       "      <th>class_79</th>\n",
       "      <th>class_8</th>\n",
       "      <th>class_9</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>00rY5F9ltW-IWf2Ev96kOg</td>\n",
       "      <td>4.517730</td>\n",
       "      <td>282</td>\n",
       "      <td>IN</td>\n",
       "      <td>39.779133</td>\n",
       "      <td>-86.164525</td>\n",
       "      <td>277.0</td>\n",
       "      <td>2.00</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>00sOoojttpdZljH8VgOU0A</td>\n",
       "      <td>3.294118</td>\n",
       "      <td>17</td>\n",
       "      <td>FL</td>\n",
       "      <td>27.996322</td>\n",
       "      <td>-82.372662</td>\n",
       "      <td>17.0</td>\n",
       "      <td>1.00</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>018SgjILDCKLR7gFSEkbGQ</td>\n",
       "      <td>4.555556</td>\n",
       "      <td>9</td>\n",
       "      <td>TN</td>\n",
       "      <td>35.908767</td>\n",
       "      <td>-86.884391</td>\n",
       "      <td>9.0</td>\n",
       "      <td>1.39</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>02nb6CI8w-2EoSEkQdk2Wg</td>\n",
       "      <td>4.161905</td>\n",
       "      <td>105</td>\n",
       "      <td>PA</td>\n",
       "      <td>39.936170</td>\n",
       "      <td>-75.146942</td>\n",
       "      <td>101.0</td>\n",
       "      <td>1.00</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>02nUjwVmJGTgGyiIi-hklg</td>\n",
       "      <td>4.545455</td>\n",
       "      <td>11</td>\n",
       "      <td>PA</td>\n",
       "      <td>39.952512</td>\n",
       "      <td>-75.171742</td>\n",
       "      <td>11.0</td>\n",
       "      <td>1.39</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>6239</td>\n",
       "      <td>zznJox6-nmXlGYNWgTDwQQ</td>\n",
       "      <td>1.633333</td>\n",
       "      <td>30</td>\n",
       "      <td>FL</td>\n",
       "      <td>27.990058</td>\n",
       "      <td>-82.730226</td>\n",
       "      <td>30.0</td>\n",
       "      <td>1.00</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>6240</td>\n",
       "      <td>ZzqqkL9mHsOnFHJvVd-10Q</td>\n",
       "      <td>3.945946</td>\n",
       "      <td>37</td>\n",
       "      <td>NJ</td>\n",
       "      <td>39.927515</td>\n",
       "      <td>-74.953437</td>\n",
       "      <td>36.0</td>\n",
       "      <td>1.00</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>6241</td>\n",
       "      <td>zZrDoiQIUmiVkifJx0h_KA</td>\n",
       "      <td>4.375000</td>\n",
       "      <td>8</td>\n",
       "      <td>CA</td>\n",
       "      <td>34.423056</td>\n",
       "      <td>-119.704515</td>\n",
       "      <td>8.0</td>\n",
       "      <td>1.39</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>6242</td>\n",
       "      <td>zzXRdzrVhfNWPHD2MeyWeA</td>\n",
       "      <td>2.066667</td>\n",
       "      <td>15</td>\n",
       "      <td>PA</td>\n",
       "      <td>40.245754</td>\n",
       "      <td>-75.342402</td>\n",
       "      <td>14.0</td>\n",
       "      <td>1.39</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>6243</td>\n",
       "      <td>zZ_xsIQfotnHe25MxQyg0g</td>\n",
       "      <td>2.213115</td>\n",
       "      <td>61</td>\n",
       "      <td>MO</td>\n",
       "      <td>38.626700</td>\n",
       "      <td>-90.335488</td>\n",
       "      <td>59.0</td>\n",
       "      <td>1.00</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>6244 rows × 163 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                 business_id     stars  rate_user_num state   latitude  \\\n",
       "0     00rY5F9ltW-IWf2Ev96kOg  4.517730            282    IN  39.779133   \n",
       "1     00sOoojttpdZljH8VgOU0A  3.294118             17    FL  27.996322   \n",
       "2     018SgjILDCKLR7gFSEkbGQ  4.555556              9    TN  35.908767   \n",
       "3     02nb6CI8w-2EoSEkQdk2Wg  4.161905            105    PA  39.936170   \n",
       "4     02nUjwVmJGTgGyiIi-hklg  4.545455             11    PA  39.952512   \n",
       "...                      ...       ...            ...   ...        ...   \n",
       "6239  zznJox6-nmXlGYNWgTDwQQ  1.633333             30    FL  27.990058   \n",
       "6240  ZzqqkL9mHsOnFHJvVd-10Q  3.945946             37    NJ  39.927515   \n",
       "6241  zZrDoiQIUmiVkifJx0h_KA  4.375000              8    CA  34.423056   \n",
       "6242  zzXRdzrVhfNWPHD2MeyWeA  2.066667             15    PA  40.245754   \n",
       "6243  zZ_xsIQfotnHe25MxQyg0g  2.213115             61    MO  38.626700   \n",
       "\n",
       "       longitude  review_count  price_level  HasTV  Caters  ...  class_71  \\\n",
       "0     -86.164525         277.0         2.00      0       0  ...       0.0   \n",
       "1     -82.372662          17.0         1.00      0       0  ...       0.0   \n",
       "2     -86.884391           9.0         1.39      0       0  ...       NaN   \n",
       "3     -75.146942         101.0         1.00      0       0  ...       0.0   \n",
       "4     -75.171742          11.0         1.39      0       0  ...       0.0   \n",
       "...          ...           ...          ...    ...     ...  ...       ...   \n",
       "6239  -82.730226          30.0         1.00      0       0  ...       0.0   \n",
       "6240  -74.953437          36.0         1.00      0       0  ...       0.0   \n",
       "6241 -119.704515           8.0         1.39      0       0  ...       0.0   \n",
       "6242  -75.342402          14.0         1.39      1       0  ...       NaN   \n",
       "6243  -90.335488          59.0         1.00      1       0  ...       0.0   \n",
       "\n",
       "      class_72  class_73  class_74  class_75  class_76  class_77  class_79  \\\n",
       "0          0.0       0.0       0.0       0.0       0.0       0.0       0.0   \n",
       "1          0.0       0.0       0.0       0.0       0.0       0.0       0.0   \n",
       "2          NaN       NaN       NaN       NaN       NaN       NaN       NaN   \n",
       "3          0.0       0.0       0.0       0.0       0.0       0.0       0.0   \n",
       "4          0.0       0.0       0.0       2.0       0.0       0.0       0.0   \n",
       "...        ...       ...       ...       ...       ...       ...       ...   \n",
       "6239       0.0       0.0       0.0       0.0       0.0       0.0       0.0   \n",
       "6240       1.0       0.0       0.0       0.0       0.0       0.0       0.0   \n",
       "6241       0.0       0.0       0.0       0.0       0.0       0.0       0.0   \n",
       "6242       NaN       NaN       NaN       NaN       NaN       NaN       NaN   \n",
       "6243       0.0       0.0       0.0       0.0       0.0       0.0       0.0   \n",
       "\n",
       "      class_8  class_9  \n",
       "0         0.0      2.0  \n",
       "1         0.0      0.0  \n",
       "2         NaN      NaN  \n",
       "3         0.0      0.0  \n",
       "4         0.0      0.0  \n",
       "...       ...      ...  \n",
       "6239      0.0      0.0  \n",
       "6240      0.0      0.0  \n",
       "6241      0.0      0.0  \n",
       "6242      NaN      NaN  \n",
       "6243      0.0      0.0  \n",
       "\n",
       "[6244 rows x 163 columns]"
      ]
     },
     "execution_count": 246,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "shop_static_info"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 247,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import statsmodels.api as sm\n",
    "from scipy import stats\n",
    "import statsmodels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 249,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# fit model\n",
    "'''\n",
    "Y variable is weighted rating\n",
    "'''\n",
    "# Fit a linear regression\n",
    "X = shop_static_info[[\n",
    "    'stars', \n",
    "    'rate_user_num', \n",
    "    'state', \n",
    "    'latitude',\n",
    "    'longitude', \n",
    "    'review_count', \n",
    "    'price_level', \n",
    "    'HasTV', \n",
    "    'Caters', \n",
    "    'OutdoorSeating', \n",
    "    'WheelchairAccessible', \n",
    "    'BusinessParking', \n",
    "    'RestaurantsDelivery', \n",
    "    'BikeParking', \n",
    "    'WiFi', \n",
    "    'Alcohol', \n",
    "    'RestaurantsTakeOut',\n",
    "    'BusinessAcceptsCreditCards', \n",
    "    'open_days', \n",
    "    'open_hours', \n",
    "    'rating', \n",
    "    'num_rating', \n",
    "    'photo_drink', \n",
    "    'photo_food', \n",
    "    'photo_inside', \n",
    "    'photo_menu',\n",
    "    'photo_outside', \n",
    "    'photo_total', \n",
    "    'user_avg_stars', \n",
    "    'user_avg_review_count', \n",
    "    'user_avg_useful', \n",
    "    'user_avg_funny', \n",
    "    'user_avg_cool', \n",
    "    'user_avg_fans', \n",
    "    'user_avg_compliment_hot', \n",
    "    'user_avg_compliment_more', \n",
    "    'user_avg_compliment_profile', \n",
    "    'user_avg_compliment_cute', \n",
    "    'user_avg_compliment_list', \n",
    "    'user_avg_compliment_note', \n",
    "    'user_avg_compliment_plain', \n",
    "    'user_avg_compliment_cool',\n",
    "    'user_avg_compliment_funny', \n",
    "    'user_avg_compliment_writer', \n",
    "    'user_avg_compliment_photos', \n",
    "    'user_yelp_years', \n",
    "    'user_avg_total_compliment',\n",
    "    'state_state', \n",
    "    'abbrev',\n",
    "    'code', \n",
    "    'full_state',\n",
    "    'Total:_Estimate',\n",
    "    'Less than $20,000_Estimate', \n",
    "    '$20,000 to $39,999_Estimate', \n",
    "    '$40,000 to $59,999_Estimate', \n",
    "    '$60,000 to $99,999_Estimate', \n",
    "    '$100,000 to $149,999_Estimate',\n",
    "    '$150,000 to $199,999_Estimate', \n",
    "    '$200,000 or more_Estimate', \n",
    "    'PAYANN', 'PCHDAPR', 'PCHADVT', 'DENSITY_2021', 'POP_2021', \n",
    "    'Total:_max', 'Less than $20,000_max', '$20,000 to $39,999_max', '$40,000 to $59,999_max', \n",
    "    '$60,000 to $99,999_max', '$100,000 to $149,999_max', '$150,000 to $199,999_max', '$200,000 or more_max',\n",
    "    'Total:_min', 'Less than $20,000_min', '$20,000 to $39,999_min', '$40,000 to $59,999_min', \n",
    "    '$60,000 to $99,999_min', '$100,000 to $149,999_min', '$150,000 to $199,999_min', '$200,000 or more_min', \n",
    "    'less_100m', 'less_500m', 'less_1km', 'less_5km', 'less_10km', 'less_50km', \n",
    "    'class_0', 'class_1', 'class_10', 'class_11', 'class_12', 'class_13', 'class_14', 'class_15', \n",
    "    'class_16', 'class_17', 'class_2', 'class_20', 'class_22', 'class_23', 'class_24', 'class_25', \n",
    "    'class_26', 'class_27', 'class_28', 'class_29', 'class_3', 'class_31', 'class_32', 'class_33', \n",
    "    'class_34', 'class_35', 'class_36', 'class_37', 'class_38', 'class_39', 'class_4', 'class_40', \n",
    "    'class_41', 'class_42', 'class_43', 'class_44', 'class_45', 'class_46', 'class_47', 'class_48', \n",
    "    'class_49', 'class_5', 'class_50', 'class_51', 'class_52', 'class_53', 'class_54', 'class_55', \n",
    "    'class_56', 'class_57', 'class_58', 'class_59', 'class_6', 'class_60', 'class_61', 'class_62', \n",
    "    'class_63', 'class_64', 'class_65', 'class_66', 'class_67', 'class_68', 'class_69', 'class_7', \n",
    "    'class_70', 'class_71', 'class_72', 'class_73', 'class_74', 'class_75', 'class_76', 'class_77', \n",
    "    'class_79', 'class_8', 'class_9'\n",
    "]] \n",
    "y = shop_static_info[ 'weighted_rating']\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 250,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/anaconda3/lib/python3.7/site-packages/ipykernel_launcher.py:1: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  \"\"\"Entry point for launching an IPython kernel.\n",
      "/opt/anaconda3/lib/python3.7/site-packages/ipykernel_launcher.py:4: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  after removing the cwd from sys.path.\n",
      "/opt/anaconda3/lib/python3.7/site-packages/pandas/core/frame.py:4263: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  method=method,\n",
      "/opt/anaconda3/lib/python3.7/site-packages/numpy/core/fromnumeric.py:2495: FutureWarning: Method .ptp is deprecated and will be removed in a future version. Use numpy.ptp instead.\n",
      "  return ptp(axis=axis, out=out, **kwargs)\n",
      "/opt/anaconda3/lib/python3.7/site-packages/statsmodels/base/model.py:1294: RuntimeWarning: invalid value encountered in true_divide\n",
      "  return self.params / self.bse\n",
      "/opt/anaconda3/lib/python3.7/site-packages/scipy/stats/_distn_infrastructure.py:901: RuntimeWarning: invalid value encountered in greater\n",
      "  return (a < x) & (x < b)\n",
      "/opt/anaconda3/lib/python3.7/site-packages/scipy/stats/_distn_infrastructure.py:901: RuntimeWarning: invalid value encountered in less\n",
      "  return (a < x) & (x < b)\n",
      "/opt/anaconda3/lib/python3.7/site-packages/scipy/stats/_distn_infrastructure.py:1892: RuntimeWarning: invalid value encountered in less_equal\n",
      "  cond2 = cond0 & (x <= _a)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<table class=\"simpletable\">\n",
       "<caption>OLS Regression Results</caption>\n",
       "<tr>\n",
       "  <th>Dep. Variable:</th>     <td>weighted_rating</td> <th>  R-squared:         </th> <td>   0.761</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Model:</th>                   <td>OLS</td>       <th>  Adj. R-squared:    </th> <td>   0.756</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Method:</th>             <td>Least Squares</td>  <th>  F-statistic:       </th> <td>   149.9</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Date:</th>             <td>Fri, 20 May 2022</td> <th>  Prob (F-statistic):</th>  <td>  0.00</td> \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Time:</th>                 <td>17:39:55</td>     <th>  Log-Likelihood:    </th> <td> -644.19</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>No. Observations:</th>      <td>  6244</td>      <th>  AIC:               </th> <td>   1550.</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Df Residuals:</th>          <td>  6113</td>      <th>  BIC:               </th> <td>   2433.</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Df Model:</th>              <td>   130</td>      <th>                     </th>     <td> </td>   \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Covariance Type:</th>      <td>nonrobust</td>    <th>                     </th>     <td> </td>   \n",
       "</tr>\n",
       "</table>\n",
       "<table class=\"simpletable\">\n",
       "<tr>\n",
       "                <td></td>                   <th>coef</th>     <th>std err</th>      <th>t</th>      <th>P>|t|</th>  <th>[0.025</th>    <th>0.975]</th>  \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>const</th>                         <td> 1.304e-07</td> <td> 2.08e-07</td> <td>    0.626</td> <td> 0.531</td> <td>-2.78e-07</td> <td> 5.39e-07</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>stars</th>                         <td>    0.4053</td> <td>    0.008</td> <td>   52.089</td> <td> 0.000</td> <td>    0.390</td> <td>    0.421</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>rate_user_num</th>                 <td>   -0.0040</td> <td>    0.001</td> <td>   -3.070</td> <td> 0.002</td> <td>   -0.007</td> <td>   -0.001</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>state</th>                         <td> 3.206e-07</td> <td> 1.38e-07</td> <td>    2.320</td> <td> 0.020</td> <td> 4.97e-08</td> <td> 5.91e-07</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>latitude</th>                      <td>    0.0035</td> <td>    0.036</td> <td>    0.100</td> <td> 0.921</td> <td>   -0.066</td> <td>    0.073</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>longitude</th>                     <td>    0.0680</td> <td>    0.029</td> <td>    2.362</td> <td> 0.018</td> <td>    0.012</td> <td>    0.124</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>review_count</th>                  <td>    0.0038</td> <td>    0.001</td> <td>    2.853</td> <td> 0.004</td> <td>    0.001</td> <td>    0.006</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>price_level</th>                   <td>    0.0087</td> <td>    0.008</td> <td>    1.112</td> <td> 0.266</td> <td>   -0.007</td> <td>    0.024</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>HasTV</th>                         <td>   -0.0554</td> <td>    0.009</td> <td>   -6.357</td> <td> 0.000</td> <td>   -0.072</td> <td>   -0.038</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Caters</th>                        <td>   -0.0027</td> <td>    0.009</td> <td>   -0.293</td> <td> 0.769</td> <td>   -0.021</td> <td>    0.015</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>OutdoorSeating</th>                <td>    0.0330</td> <td>    0.008</td> <td>    4.185</td> <td> 0.000</td> <td>    0.018</td> <td>    0.048</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>WheelchairAccessible</th>          <td>   -0.0381</td> <td>    0.009</td> <td>   -4.027</td> <td> 0.000</td> <td>   -0.057</td> <td>   -0.020</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>BusinessParking</th>               <td>    0.0038</td> <td>    0.008</td> <td>    0.458</td> <td> 0.647</td> <td>   -0.012</td> <td>    0.020</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>RestaurantsDelivery</th>           <td>    0.0152</td> <td>    0.009</td> <td>    1.661</td> <td> 0.097</td> <td>   -0.003</td> <td>    0.033</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>BikeParking</th>                   <td>    0.0140</td> <td>    0.010</td> <td>    1.394</td> <td> 0.163</td> <td>   -0.006</td> <td>    0.034</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>WiFi</th>                          <td>   -0.0061</td> <td>    0.007</td> <td>   -0.850</td> <td> 0.395</td> <td>   -0.020</td> <td>    0.008</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Alcohol</th>                       <td>   -0.0061</td> <td>    0.007</td> <td>   -0.850</td> <td> 0.395</td> <td>   -0.020</td> <td>    0.008</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>RestaurantsTakeOut</th>            <td>   -0.0365</td> <td>    0.018</td> <td>   -1.977</td> <td> 0.048</td> <td>   -0.073</td> <td>   -0.000</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>BusinessAcceptsCreditCards</th>    <td>   -0.0725</td> <td>    0.026</td> <td>   -2.780</td> <td> 0.005</td> <td>   -0.124</td> <td>   -0.021</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>open_days</th>                     <td>    0.0147</td> <td>    0.003</td> <td>    5.676</td> <td> 0.000</td> <td>    0.010</td> <td>    0.020</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>open_hours</th>                    <td>   -0.0010</td> <td>    0.000</td> <td>   -8.879</td> <td> 0.000</td> <td>   -0.001</td> <td>   -0.001</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>rating</th>                        <td>    0.1673</td> <td>    0.004</td> <td>   41.026</td> <td> 0.000</td> <td>    0.159</td> <td>    0.175</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>num_rating</th>                    <td> 5.455e-05</td> <td> 4.46e-06</td> <td>   12.229</td> <td> 0.000</td> <td> 4.58e-05</td> <td> 6.33e-05</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>photo_drink</th>                   <td>    0.0123</td> <td>    0.004</td> <td>    2.745</td> <td> 0.006</td> <td>    0.004</td> <td>    0.021</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>photo_food</th>                    <td>    0.0008</td> <td>    0.004</td> <td>    0.210</td> <td> 0.833</td> <td>   -0.007</td> <td>    0.008</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>photo_inside</th>                  <td>   -0.0012</td> <td>    0.004</td> <td>   -0.322</td> <td> 0.748</td> <td>   -0.009</td> <td>    0.006</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>photo_menu</th>                    <td>   -0.0115</td> <td>    0.016</td> <td>   -0.715</td> <td> 0.475</td> <td>   -0.043</td> <td>    0.020</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>photo_outside</th>                 <td>   -0.0037</td> <td>    0.006</td> <td>   -0.612</td> <td> 0.541</td> <td>   -0.016</td> <td>    0.008</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>photo_total</th>                   <td>   -0.0034</td> <td>    0.004</td> <td>   -0.850</td> <td> 0.395</td> <td>   -0.011</td> <td>    0.004</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>user_avg_stars</th>                <td>   -0.0468</td> <td>    0.018</td> <td>   -2.643</td> <td> 0.008</td> <td>   -0.081</td> <td>   -0.012</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>user_avg_review_count</th>         <td>   -0.0002</td> <td> 5.02e-05</td> <td>   -3.875</td> <td> 0.000</td> <td>   -0.000</td> <td>-9.61e-05</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>user_avg_useful</th>               <td>  2.19e-05</td> <td> 4.04e-05</td> <td>    0.542</td> <td> 0.588</td> <td>-5.73e-05</td> <td>    0.000</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>user_avg_funny</th>                <td> 1.506e-05</td> <td> 2.77e-05</td> <td>    0.544</td> <td> 0.586</td> <td>-3.92e-05</td> <td> 6.93e-05</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>user_avg_cool</th>                 <td> 1.195e-06</td> <td> 5.18e-05</td> <td>    0.023</td> <td> 0.982</td> <td>   -0.000</td> <td>    0.000</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>user_avg_fans</th>                 <td>   -0.0004</td> <td>    0.000</td> <td>   -1.139</td> <td> 0.255</td> <td>   -0.001</td> <td>    0.000</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>user_avg_compliment_hot</th>       <td>   -0.0004</td> <td>    0.000</td> <td>   -1.048</td> <td> 0.295</td> <td>   -0.001</td> <td>    0.000</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>user_avg_compliment_more</th>      <td>    0.0034</td> <td>    0.003</td> <td>    1.296</td> <td> 0.195</td> <td>   -0.002</td> <td>    0.008</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>user_avg_compliment_profile</th>   <td>   -0.0048</td> <td>    0.002</td> <td>   -2.004</td> <td> 0.045</td> <td>   -0.009</td> <td>   -0.000</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>user_avg_compliment_cute</th>      <td>   -0.0018</td> <td>    0.003</td> <td>   -0.679</td> <td> 0.497</td> <td>   -0.007</td> <td>    0.003</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>user_avg_compliment_list</th>      <td>    0.0094</td> <td>    0.004</td> <td>    2.396</td> <td> 0.017</td> <td>    0.002</td> <td>    0.017</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>user_avg_compliment_note</th>      <td>   -0.0007</td> <td>    0.000</td> <td>   -3.643</td> <td> 0.000</td> <td>   -0.001</td> <td>   -0.000</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>user_avg_compliment_plain</th>     <td>   -0.0005</td> <td>    0.000</td> <td>   -2.699</td> <td> 0.007</td> <td>   -0.001</td> <td>   -0.000</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>user_avg_compliment_cool</th>      <td>   -0.0009</td> <td>    0.000</td> <td>   -3.655</td> <td> 0.000</td> <td>   -0.001</td> <td>   -0.000</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>user_avg_compliment_funny</th>     <td>   -0.0009</td> <td>    0.000</td> <td>   -3.655</td> <td> 0.000</td> <td>   -0.001</td> <td>   -0.000</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>user_avg_compliment_writer</th>    <td>   -0.0010</td> <td>    0.000</td> <td>   -2.325</td> <td> 0.020</td> <td>   -0.002</td> <td>   -0.000</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>user_avg_compliment_photos</th>    <td>   -0.0009</td> <td>    0.000</td> <td>   -3.704</td> <td> 0.000</td> <td>   -0.001</td> <td>   -0.000</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>user_yelp_years</th>               <td>-4.328e-10</td> <td> 9.11e-11</td> <td>   -4.752</td> <td> 0.000</td> <td>-6.11e-10</td> <td>-2.54e-10</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>user_avg_total_compliment</th>     <td>    0.0007</td> <td>    0.000</td> <td>    3.650</td> <td> 0.000</td> <td>    0.000</td> <td>    0.001</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>state_state</th>                   <td> 3.205e-07</td> <td> 1.38e-07</td> <td>    2.319</td> <td> 0.020</td> <td> 4.96e-08</td> <td> 5.91e-07</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>abbrev</th>                        <td> 3.205e-07</td> <td> 1.38e-07</td> <td>    2.319</td> <td> 0.020</td> <td> 4.96e-08</td> <td> 5.91e-07</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>code</th>                          <td> 3.205e-07</td> <td> 1.38e-07</td> <td>    2.319</td> <td> 0.020</td> <td> 4.96e-08</td> <td> 5.91e-07</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>full_state</th>                    <td> 3.205e-07</td> <td> 1.38e-07</td> <td>    2.319</td> <td> 0.020</td> <td> 4.96e-08</td> <td> 5.91e-07</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Total:_Estimate</th>               <td>-3.563e-06</td> <td> 1.73e-06</td> <td>   -2.063</td> <td> 0.039</td> <td>-6.95e-06</td> <td>-1.77e-07</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Less than $20,000_Estimate</th>    <td>-1.831e-05</td> <td> 7.26e-06</td> <td>   -2.523</td> <td> 0.012</td> <td>-3.25e-05</td> <td>-4.08e-06</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>$20,000 to $39,999_Estimate</th>   <td> 4.729e-06</td> <td> 4.44e-06</td> <td>    1.065</td> <td> 0.287</td> <td>-3.98e-06</td> <td> 1.34e-05</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>$40,000 to $59,999_Estimate</th>   <td> -3.42e-06</td> <td> 6.27e-06</td> <td>   -0.545</td> <td> 0.586</td> <td>-1.57e-05</td> <td> 8.87e-06</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>$60,000 to $99,999_Estimate</th>   <td> 1.779e-05</td> <td> 9.45e-06</td> <td>    1.882</td> <td> 0.060</td> <td>-7.42e-07</td> <td> 3.63e-05</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>$100,000 to $149,999_Estimate</th> <td>-2.808e-05</td> <td> 1.16e-05</td> <td>   -2.418</td> <td> 0.016</td> <td>-5.08e-05</td> <td>-5.32e-06</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>$150,000 to $199,999_Estimate</th> <td> 3.112e-05</td> <td> 1.17e-05</td> <td>    2.656</td> <td> 0.008</td> <td> 8.15e-06</td> <td> 5.41e-05</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>$200,000 or more_Estimate</th>     <td>-7.395e-06</td> <td> 3.24e-06</td> <td>   -2.280</td> <td> 0.023</td> <td>-1.38e-05</td> <td>-1.04e-06</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>PAYANN</th>                        <td> 1.267e-06</td> <td> 7.26e-07</td> <td>    1.746</td> <td> 0.081</td> <td>-1.56e-07</td> <td> 2.69e-06</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>PCHDAPR</th>                       <td>   -0.0001</td> <td> 5.28e-05</td> <td>   -2.069</td> <td> 0.039</td> <td>   -0.000</td> <td>-5.73e-06</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>PCHADVT</th>                       <td>    0.0003</td> <td>    0.000</td> <td>    2.313</td> <td> 0.021</td> <td> 4.52e-05</td> <td>    0.001</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>DENSITY_2021</th>                  <td>-2.198e-05</td> <td> 1.45e-05</td> <td>   -1.516</td> <td> 0.130</td> <td>-5.04e-05</td> <td> 6.44e-06</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>POP_2021</th>                      <td> 4.163e-06</td> <td> 1.82e-06</td> <td>    2.284</td> <td> 0.022</td> <td> 5.89e-07</td> <td> 7.74e-06</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Total:_max</th>                    <td> 7.089e-05</td> <td> 3.27e-05</td> <td>    2.170</td> <td> 0.030</td> <td> 6.85e-06</td> <td>    0.000</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Less than $20,000_max</th>         <td>-6.519e-05</td> <td> 3.93e-05</td> <td>   -1.658</td> <td> 0.097</td> <td>   -0.000</td> <td> 1.19e-05</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>$20,000 to $39,999_max</th>        <td> 7.801e-05</td> <td> 3.44e-05</td> <td>    2.265</td> <td> 0.024</td> <td> 1.05e-05</td> <td>    0.000</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>$40,000 to $59,999_max</th>        <td>    0.0002</td> <td> 7.81e-05</td> <td>    2.342</td> <td> 0.019</td> <td> 2.98e-05</td> <td>    0.000</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>$60,000 to $99,999_max</th>        <td>    0.0002</td> <td>    0.000</td> <td>    2.228</td> <td> 0.026</td> <td> 2.82e-05</td> <td>    0.000</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>$100,000 to $149,999_max</th>      <td> 7.098e-05</td> <td> 3.76e-05</td> <td>    1.887</td> <td> 0.059</td> <td>-2.74e-06</td> <td>    0.000</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>$150,000 to $199,999_max</th>      <td> 4.717e-05</td> <td>  1.5e-05</td> <td>    3.145</td> <td> 0.002</td> <td> 1.78e-05</td> <td> 7.66e-05</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>$200,000 or more_max</th>          <td> -7.57e-06</td> <td> 1.78e-05</td> <td>   -0.425</td> <td> 0.671</td> <td>-4.25e-05</td> <td> 2.73e-05</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Total:_min</th>                    <td>-7.801e-05</td> <td> 3.61e-05</td> <td>   -2.160</td> <td> 0.031</td> <td>   -0.000</td> <td>-7.23e-06</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Less than $20,000_min</th>         <td> 2.857e-05</td> <td> 2.91e-05</td> <td>    0.981</td> <td> 0.326</td> <td>-2.85e-05</td> <td> 8.56e-05</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>$20,000 to $39,999_min</th>        <td>-6.855e-05</td> <td> 2.78e-05</td> <td>   -2.464</td> <td> 0.014</td> <td>   -0.000</td> <td> -1.4e-05</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>$40,000 to $59,999_min</th>        <td>   -0.0002</td> <td> 8.05e-05</td> <td>   -2.356</td> <td> 0.019</td> <td>   -0.000</td> <td>-3.18e-05</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>$60,000 to $99,999_min</th>        <td>   -0.0002</td> <td> 8.95e-05</td> <td>   -2.230</td> <td> 0.026</td> <td>   -0.000</td> <td>-2.42e-05</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>$100,000 to $149,999_min</th>      <td>   -0.0001</td> <td> 5.82e-05</td> <td>   -2.185</td> <td> 0.029</td> <td>   -0.000</td> <td>-1.31e-05</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>$150,000 to $199,999_min</th>      <td> 1.506e-05</td> <td>  1.3e-05</td> <td>    1.155</td> <td> 0.248</td> <td>-1.05e-05</td> <td> 4.06e-05</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>$200,000 or more_min</th>          <td>-7.219e-06</td> <td> 1.72e-05</td> <td>   -0.421</td> <td> 0.674</td> <td>-4.09e-05</td> <td> 2.64e-05</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>less_100m</th>                     <td>   -0.0069</td> <td>    0.003</td> <td>   -2.263</td> <td> 0.024</td> <td>   -0.013</td> <td>   -0.001</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>less_500m</th>                     <td>   -0.0004</td> <td>    0.001</td> <td>   -0.537</td> <td> 0.591</td> <td>   -0.002</td> <td>    0.001</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>less_1km</th>                      <td>    0.0001</td> <td>    0.000</td> <td>    0.352</td> <td> 0.725</td> <td>   -0.001</td> <td>    0.001</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>less_5km</th>                      <td>   -0.0001</td> <td> 5.73e-05</td> <td>   -2.610</td> <td> 0.009</td> <td>   -0.000</td> <td>-3.72e-05</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>less_10km</th>                     <td> 4.462e-05</td> <td> 3.83e-05</td> <td>    1.165</td> <td> 0.244</td> <td>-3.05e-05</td> <td>    0.000</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>less_50km</th>                     <td>-7.708e-05</td> <td> 2.55e-05</td> <td>   -3.028</td> <td> 0.002</td> <td>   -0.000</td> <td>-2.72e-05</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>class_0</th>                       <td>   -0.0005</td> <td>    0.001</td> <td>   -0.771</td> <td> 0.441</td> <td>   -0.002</td> <td>    0.001</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>class_1</th>                       <td>   -0.0086</td> <td>    0.010</td> <td>   -0.833</td> <td> 0.405</td> <td>   -0.029</td> <td>    0.012</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>class_10</th>                      <td>   -0.0531</td> <td>    0.048</td> <td>   -1.101</td> <td> 0.271</td> <td>   -0.148</td> <td>    0.041</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>class_11</th>                      <td>    0.0483</td> <td>    0.036</td> <td>    1.354</td> <td> 0.176</td> <td>   -0.022</td> <td>    0.118</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>class_12</th>                      <td>   -0.0676</td> <td>    0.045</td> <td>   -1.492</td> <td> 0.136</td> <td>   -0.157</td> <td>    0.021</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>class_13</th>                      <td>    0.0112</td> <td>    0.012</td> <td>    0.920</td> <td> 0.357</td> <td>   -0.013</td> <td>    0.035</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>class_14</th>                      <td>   -0.0087</td> <td>    0.048</td> <td>   -0.182</td> <td> 0.856</td> <td>   -0.102</td> <td>    0.085</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>class_15</th>                      <td>    0.0187</td> <td>    0.033</td> <td>    0.560</td> <td> 0.575</td> <td>   -0.047</td> <td>    0.084</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>class_16</th>                      <td>    0.0168</td> <td>    0.019</td> <td>    0.868</td> <td> 0.385</td> <td>   -0.021</td> <td>    0.055</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>class_17</th>                      <td>  6.07e-18</td> <td> 1.99e-16</td> <td>    0.030</td> <td> 0.976</td> <td>-3.85e-16</td> <td> 3.97e-16</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>class_2</th>                       <td>    0.0104</td> <td>    0.004</td> <td>    2.601</td> <td> 0.009</td> <td>    0.003</td> <td>    0.018</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>class_20</th>                      <td>   -0.0774</td> <td>    0.283</td> <td>   -0.274</td> <td> 0.784</td> <td>   -0.631</td> <td>    0.476</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>class_22</th>                      <td>-1.727e-16</td> <td> 4.82e-16</td> <td>   -0.358</td> <td> 0.720</td> <td>-1.12e-15</td> <td> 7.72e-16</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>class_23</th>                      <td>    0.0448</td> <td>    0.102</td> <td>    0.441</td> <td> 0.659</td> <td>   -0.155</td> <td>    0.244</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>class_24</th>                      <td>    0.0044</td> <td>    0.021</td> <td>    0.209</td> <td> 0.834</td> <td>   -0.037</td> <td>    0.046</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>class_25</th>                      <td>    0.0078</td> <td>    0.008</td> <td>    1.030</td> <td> 0.303</td> <td>   -0.007</td> <td>    0.023</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>class_26</th>                      <td>    0.0061</td> <td>    0.016</td> <td>    0.386</td> <td> 0.699</td> <td>   -0.025</td> <td>    0.037</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>class_27</th>                      <td>   -0.0065</td> <td>    0.028</td> <td>   -0.229</td> <td> 0.819</td> <td>   -0.062</td> <td>    0.049</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>class_28</th>                      <td>   -0.0396</td> <td>    0.019</td> <td>   -2.057</td> <td> 0.040</td> <td>   -0.077</td> <td>   -0.002</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>class_29</th>                      <td>    0.0094</td> <td>    0.077</td> <td>    0.122</td> <td> 0.903</td> <td>   -0.141</td> <td>    0.160</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>class_3</th>                       <td>    0.0013</td> <td>    0.017</td> <td>    0.076</td> <td> 0.940</td> <td>   -0.031</td> <td>    0.034</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>class_31</th>                      <td>  2.29e-16</td> <td> 5.33e-16</td> <td>    0.430</td> <td> 0.667</td> <td>-8.16e-16</td> <td> 1.27e-15</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>class_32</th>                      <td>   -0.0192</td> <td>    0.041</td> <td>   -0.465</td> <td> 0.642</td> <td>   -0.100</td> <td>    0.062</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>class_33</th>                      <td>   -0.0341</td> <td>    0.087</td> <td>   -0.393</td> <td> 0.694</td> <td>   -0.204</td> <td>    0.136</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>class_34</th>                      <td>    0.0730</td> <td>    0.117</td> <td>    0.624</td> <td> 0.532</td> <td>   -0.156</td> <td>    0.302</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>class_35</th>                      <td>-1.389e-17</td> <td> 2.74e-16</td> <td>   -0.051</td> <td> 0.960</td> <td> -5.5e-16</td> <td> 5.23e-16</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>class_36</th>                      <td>    0.0403</td> <td>    0.069</td> <td>    0.581</td> <td> 0.561</td> <td>   -0.096</td> <td>    0.176</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>class_37</th>                      <td>    0.0688</td> <td>    0.137</td> <td>    0.504</td> <td> 0.614</td> <td>   -0.199</td> <td>    0.336</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>class_38</th>                      <td> -1.09e-17</td> <td> 5.84e-17</td> <td>   -0.187</td> <td> 0.852</td> <td>-1.25e-16</td> <td> 1.04e-16</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>class_39</th>                      <td>    0.0042</td> <td>    0.001</td> <td>    2.792</td> <td> 0.005</td> <td>    0.001</td> <td>    0.007</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>class_4</th>                       <td>    0.0343</td> <td>    0.138</td> <td>    0.249</td> <td> 0.804</td> <td>   -0.236</td> <td>    0.305</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>class_40</th>                      <td>   -0.0042</td> <td>    0.004</td> <td>   -1.033</td> <td> 0.302</td> <td>   -0.012</td> <td>    0.004</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>class_41</th>                      <td>    0.0021</td> <td>    0.002</td> <td>    1.304</td> <td> 0.192</td> <td>   -0.001</td> <td>    0.005</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>class_42</th>                      <td>    0.0097</td> <td>    0.008</td> <td>    1.208</td> <td> 0.227</td> <td>   -0.006</td> <td>    0.026</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>class_43</th>                      <td>    0.0079</td> <td>    0.012</td> <td>    0.679</td> <td> 0.497</td> <td>   -0.015</td> <td>    0.031</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>class_44</th>                      <td>    0.0004</td> <td>    0.007</td> <td>    0.050</td> <td> 0.960</td> <td>   -0.013</td> <td>    0.014</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>class_45</th>                      <td>   -0.0008</td> <td>    0.003</td> <td>   -0.294</td> <td> 0.769</td> <td>   -0.006</td> <td>    0.004</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>class_46</th>                      <td>    0.0103</td> <td>    0.011</td> <td>    0.898</td> <td> 0.369</td> <td>   -0.012</td> <td>    0.033</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>class_47</th>                      <td>    0.0021</td> <td>    0.018</td> <td>    0.112</td> <td> 0.911</td> <td>   -0.034</td> <td>    0.038</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>class_48</th>                      <td>    0.0009</td> <td>    0.004</td> <td>    0.203</td> <td> 0.840</td> <td>   -0.007</td> <td>    0.009</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>class_49</th>                      <td>   -0.0033</td> <td>    0.012</td> <td>   -0.269</td> <td> 0.788</td> <td>   -0.028</td> <td>    0.021</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>class_5</th>                       <td>    0.1283</td> <td>    0.075</td> <td>    1.704</td> <td> 0.089</td> <td>   -0.019</td> <td>    0.276</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>class_50</th>                      <td>    0.0121</td> <td>    0.012</td> <td>    0.966</td> <td> 0.334</td> <td>   -0.012</td> <td>    0.037</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>class_51</th>                      <td>   -0.0013</td> <td>    0.009</td> <td>   -0.134</td> <td> 0.893</td> <td>   -0.020</td> <td>    0.017</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>class_52</th>                      <td>   -0.0019</td> <td>    0.010</td> <td>   -0.196</td> <td> 0.845</td> <td>   -0.021</td> <td>    0.017</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>class_53</th>                      <td>    0.0055</td> <td>    0.008</td> <td>    0.645</td> <td> 0.519</td> <td>   -0.011</td> <td>    0.022</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>class_54</th>                      <td>    0.0046</td> <td>    0.002</td> <td>    2.248</td> <td> 0.025</td> <td>    0.001</td> <td>    0.009</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>class_55</th>                      <td>    0.0007</td> <td>    0.003</td> <td>    0.226</td> <td> 0.821</td> <td>   -0.006</td> <td>    0.007</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>class_56</th>                      <td> 9.049e-05</td> <td>    0.001</td> <td>    0.116</td> <td> 0.908</td> <td>   -0.001</td> <td>    0.002</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>class_57</th>                      <td>    0.0041</td> <td>    0.009</td> <td>    0.446</td> <td> 0.656</td> <td>   -0.014</td> <td>    0.022</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>class_58</th>                      <td>    0.0019</td> <td>    0.002</td> <td>    0.918</td> <td> 0.359</td> <td>   -0.002</td> <td>    0.006</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>class_59</th>                      <td>   -0.0424</td> <td>    0.051</td> <td>   -0.833</td> <td> 0.405</td> <td>   -0.142</td> <td>    0.057</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>class_6</th>                       <td>   -0.0339</td> <td>    0.121</td> <td>   -0.281</td> <td> 0.779</td> <td>   -0.270</td> <td>    0.203</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>class_60</th>                      <td>    0.0007</td> <td>    0.003</td> <td>    0.210</td> <td> 0.834</td> <td>   -0.006</td> <td>    0.007</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>class_61</th>                      <td>   -0.0433</td> <td>    0.036</td> <td>   -1.206</td> <td> 0.228</td> <td>   -0.114</td> <td>    0.027</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>class_62</th>                      <td>    0.0074</td> <td>    0.005</td> <td>    1.428</td> <td> 0.153</td> <td>   -0.003</td> <td>    0.018</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>class_63</th>                      <td>    0.0141</td> <td>    0.011</td> <td>    1.265</td> <td> 0.206</td> <td>   -0.008</td> <td>    0.036</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>class_64</th>                      <td>   -0.1327</td> <td>    0.098</td> <td>   -1.359</td> <td> 0.174</td> <td>   -0.324</td> <td>    0.059</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>class_65</th>                      <td>   -0.0204</td> <td>    0.056</td> <td>   -0.366</td> <td> 0.714</td> <td>   -0.130</td> <td>    0.089</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>class_66</th>                      <td>    0.1290</td> <td>    0.094</td> <td>    1.374</td> <td> 0.169</td> <td>   -0.055</td> <td>    0.313</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>class_67</th>                      <td>    0.0162</td> <td>    0.013</td> <td>    1.219</td> <td> 0.223</td> <td>   -0.010</td> <td>    0.042</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>class_68</th>                      <td>    0.0081</td> <td>    0.017</td> <td>    0.470</td> <td> 0.639</td> <td>   -0.026</td> <td>    0.042</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>class_69</th>                      <td>   -0.0018</td> <td>    0.018</td> <td>   -0.099</td> <td> 0.921</td> <td>   -0.036</td> <td>    0.033</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>class_7</th>                       <td>   -0.0016</td> <td>    0.033</td> <td>   -0.049</td> <td> 0.961</td> <td>   -0.067</td> <td>    0.064</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>class_70</th>                      <td>         0</td> <td>        0</td> <td>      nan</td> <td>   nan</td> <td>        0</td> <td>        0</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>class_71</th>                      <td>    0.0070</td> <td>    0.025</td> <td>    0.281</td> <td> 0.778</td> <td>   -0.042</td> <td>    0.056</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>class_72</th>                      <td>   -0.0014</td> <td>    0.010</td> <td>   -0.142</td> <td> 0.887</td> <td>   -0.021</td> <td>    0.018</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>class_73</th>                      <td>    0.0028</td> <td>    0.011</td> <td>    0.250</td> <td> 0.803</td> <td>   -0.019</td> <td>    0.024</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>class_74</th>                      <td>   -0.0005</td> <td>    0.009</td> <td>   -0.056</td> <td> 0.956</td> <td>   -0.019</td> <td>    0.018</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>class_75</th>                      <td>    0.0027</td> <td>    0.006</td> <td>    0.477</td> <td> 0.633</td> <td>   -0.008</td> <td>    0.014</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>class_76</th>                      <td>    0.0107</td> <td>    0.083</td> <td>    0.128</td> <td> 0.898</td> <td>   -0.152</td> <td>    0.173</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>class_77</th>                      <td>    0.0281</td> <td>    0.019</td> <td>    1.511</td> <td> 0.131</td> <td>   -0.008</td> <td>    0.065</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>class_79</th>                      <td>    0.0002</td> <td>    0.057</td> <td>    0.004</td> <td> 0.997</td> <td>   -0.111</td> <td>    0.112</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>class_8</th>                       <td>   -0.0454</td> <td>    0.279</td> <td>   -0.163</td> <td> 0.871</td> <td>   -0.591</td> <td>    0.501</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>class_9</th>                       <td>   -0.0092</td> <td>    0.012</td> <td>   -0.796</td> <td> 0.426</td> <td>   -0.032</td> <td>    0.013</td>\n",
       "</tr>\n",
       "</table>\n",
       "<table class=\"simpletable\">\n",
       "<tr>\n",
       "  <th>Omnibus:</th>       <td>740.783</td> <th>  Durbin-Watson:     </th> <td>   1.933</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Prob(Omnibus):</th> <td> 0.000</td>  <th>  Jarque-Bera (JB):  </th> <td>2998.072</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Skew:</th>          <td>-0.537</td>  <th>  Prob(JB):          </th> <td>    0.00</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Kurtosis:</th>      <td> 6.220</td>  <th>  Cond. No.          </th> <td>3.36e+19</td>\n",
       "</tr>\n",
       "</table><br/><br/>Warnings:<br/>[1] Standard Errors assume that the covariance matrix of the errors is correctly specified.<br/>[2] The smallest eigenvalue is 3.91e-19. This might indicate that there are<br/>strong multicollinearity problems or that the design matrix is singular."
      ],
      "text/plain": [
       "<class 'statsmodels.iolib.summary.Summary'>\n",
       "\"\"\"\n",
       "                            OLS Regression Results                            \n",
       "==============================================================================\n",
       "Dep. Variable:        weighted_rating   R-squared:                       0.761\n",
       "Model:                            OLS   Adj. R-squared:                  0.756\n",
       "Method:                 Least Squares   F-statistic:                     149.9\n",
       "Date:                Fri, 20 May 2022   Prob (F-statistic):               0.00\n",
       "Time:                        17:39:55   Log-Likelihood:                -644.19\n",
       "No. Observations:                6244   AIC:                             1550.\n",
       "Df Residuals:                    6113   BIC:                             2433.\n",
       "Df Model:                         130                                         \n",
       "Covariance Type:            nonrobust                                         \n",
       "=================================================================================================\n",
       "                                    coef    std err          t      P>|t|      [0.025      0.975]\n",
       "-------------------------------------------------------------------------------------------------\n",
       "const                          1.304e-07   2.08e-07      0.626      0.531   -2.78e-07    5.39e-07\n",
       "stars                             0.4053      0.008     52.089      0.000       0.390       0.421\n",
       "rate_user_num                    -0.0040      0.001     -3.070      0.002      -0.007      -0.001\n",
       "state                          3.206e-07   1.38e-07      2.320      0.020    4.97e-08    5.91e-07\n",
       "latitude                          0.0035      0.036      0.100      0.921      -0.066       0.073\n",
       "longitude                         0.0680      0.029      2.362      0.018       0.012       0.124\n",
       "review_count                      0.0038      0.001      2.853      0.004       0.001       0.006\n",
       "price_level                       0.0087      0.008      1.112      0.266      -0.007       0.024\n",
       "HasTV                            -0.0554      0.009     -6.357      0.000      -0.072      -0.038\n",
       "Caters                           -0.0027      0.009     -0.293      0.769      -0.021       0.015\n",
       "OutdoorSeating                    0.0330      0.008      4.185      0.000       0.018       0.048\n",
       "WheelchairAccessible             -0.0381      0.009     -4.027      0.000      -0.057      -0.020\n",
       "BusinessParking                   0.0038      0.008      0.458      0.647      -0.012       0.020\n",
       "RestaurantsDelivery               0.0152      0.009      1.661      0.097      -0.003       0.033\n",
       "BikeParking                       0.0140      0.010      1.394      0.163      -0.006       0.034\n",
       "WiFi                             -0.0061      0.007     -0.850      0.395      -0.020       0.008\n",
       "Alcohol                          -0.0061      0.007     -0.850      0.395      -0.020       0.008\n",
       "RestaurantsTakeOut               -0.0365      0.018     -1.977      0.048      -0.073      -0.000\n",
       "BusinessAcceptsCreditCards       -0.0725      0.026     -2.780      0.005      -0.124      -0.021\n",
       "open_days                         0.0147      0.003      5.676      0.000       0.010       0.020\n",
       "open_hours                       -0.0010      0.000     -8.879      0.000      -0.001      -0.001\n",
       "rating                            0.1673      0.004     41.026      0.000       0.159       0.175\n",
       "num_rating                     5.455e-05   4.46e-06     12.229      0.000    4.58e-05    6.33e-05\n",
       "photo_drink                       0.0123      0.004      2.745      0.006       0.004       0.021\n",
       "photo_food                        0.0008      0.004      0.210      0.833      -0.007       0.008\n",
       "photo_inside                     -0.0012      0.004     -0.322      0.748      -0.009       0.006\n",
       "photo_menu                       -0.0115      0.016     -0.715      0.475      -0.043       0.020\n",
       "photo_outside                    -0.0037      0.006     -0.612      0.541      -0.016       0.008\n",
       "photo_total                      -0.0034      0.004     -0.850      0.395      -0.011       0.004\n",
       "user_avg_stars                   -0.0468      0.018     -2.643      0.008      -0.081      -0.012\n",
       "user_avg_review_count            -0.0002   5.02e-05     -3.875      0.000      -0.000   -9.61e-05\n",
       "user_avg_useful                 2.19e-05   4.04e-05      0.542      0.588   -5.73e-05       0.000\n",
       "user_avg_funny                 1.506e-05   2.77e-05      0.544      0.586   -3.92e-05    6.93e-05\n",
       "user_avg_cool                  1.195e-06   5.18e-05      0.023      0.982      -0.000       0.000\n",
       "user_avg_fans                    -0.0004      0.000     -1.139      0.255      -0.001       0.000\n",
       "user_avg_compliment_hot          -0.0004      0.000     -1.048      0.295      -0.001       0.000\n",
       "user_avg_compliment_more          0.0034      0.003      1.296      0.195      -0.002       0.008\n",
       "user_avg_compliment_profile      -0.0048      0.002     -2.004      0.045      -0.009      -0.000\n",
       "user_avg_compliment_cute         -0.0018      0.003     -0.679      0.497      -0.007       0.003\n",
       "user_avg_compliment_list          0.0094      0.004      2.396      0.017       0.002       0.017\n",
       "user_avg_compliment_note         -0.0007      0.000     -3.643      0.000      -0.001      -0.000\n",
       "user_avg_compliment_plain        -0.0005      0.000     -2.699      0.007      -0.001      -0.000\n",
       "user_avg_compliment_cool         -0.0009      0.000     -3.655      0.000      -0.001      -0.000\n",
       "user_avg_compliment_funny        -0.0009      0.000     -3.655      0.000      -0.001      -0.000\n",
       "user_avg_compliment_writer       -0.0010      0.000     -2.325      0.020      -0.002      -0.000\n",
       "user_avg_compliment_photos       -0.0009      0.000     -3.704      0.000      -0.001      -0.000\n",
       "user_yelp_years               -4.328e-10   9.11e-11     -4.752      0.000   -6.11e-10   -2.54e-10\n",
       "user_avg_total_compliment         0.0007      0.000      3.650      0.000       0.000       0.001\n",
       "state_state                    3.205e-07   1.38e-07      2.319      0.020    4.96e-08    5.91e-07\n",
       "abbrev                         3.205e-07   1.38e-07      2.319      0.020    4.96e-08    5.91e-07\n",
       "code                           3.205e-07   1.38e-07      2.319      0.020    4.96e-08    5.91e-07\n",
       "full_state                     3.205e-07   1.38e-07      2.319      0.020    4.96e-08    5.91e-07\n",
       "Total:_Estimate               -3.563e-06   1.73e-06     -2.063      0.039   -6.95e-06   -1.77e-07\n",
       "Less than $20,000_Estimate    -1.831e-05   7.26e-06     -2.523      0.012   -3.25e-05   -4.08e-06\n",
       "$20,000 to $39,999_Estimate    4.729e-06   4.44e-06      1.065      0.287   -3.98e-06    1.34e-05\n",
       "$40,000 to $59,999_Estimate    -3.42e-06   6.27e-06     -0.545      0.586   -1.57e-05    8.87e-06\n",
       "$60,000 to $99,999_Estimate    1.779e-05   9.45e-06      1.882      0.060   -7.42e-07    3.63e-05\n",
       "$100,000 to $149,999_Estimate -2.808e-05   1.16e-05     -2.418      0.016   -5.08e-05   -5.32e-06\n",
       "$150,000 to $199,999_Estimate  3.112e-05   1.17e-05      2.656      0.008    8.15e-06    5.41e-05\n",
       "$200,000 or more_Estimate     -7.395e-06   3.24e-06     -2.280      0.023   -1.38e-05   -1.04e-06\n",
       "PAYANN                         1.267e-06   7.26e-07      1.746      0.081   -1.56e-07    2.69e-06\n",
       "PCHDAPR                          -0.0001   5.28e-05     -2.069      0.039      -0.000   -5.73e-06\n",
       "PCHADVT                           0.0003      0.000      2.313      0.021    4.52e-05       0.001\n",
       "DENSITY_2021                  -2.198e-05   1.45e-05     -1.516      0.130   -5.04e-05    6.44e-06\n",
       "POP_2021                       4.163e-06   1.82e-06      2.284      0.022    5.89e-07    7.74e-06\n",
       "Total:_max                     7.089e-05   3.27e-05      2.170      0.030    6.85e-06       0.000\n",
       "Less than $20,000_max         -6.519e-05   3.93e-05     -1.658      0.097      -0.000    1.19e-05\n",
       "$20,000 to $39,999_max         7.801e-05   3.44e-05      2.265      0.024    1.05e-05       0.000\n",
       "$40,000 to $59,999_max            0.0002   7.81e-05      2.342      0.019    2.98e-05       0.000\n",
       "$60,000 to $99,999_max            0.0002      0.000      2.228      0.026    2.82e-05       0.000\n",
       "$100,000 to $149,999_max       7.098e-05   3.76e-05      1.887      0.059   -2.74e-06       0.000\n",
       "$150,000 to $199,999_max       4.717e-05    1.5e-05      3.145      0.002    1.78e-05    7.66e-05\n",
       "$200,000 or more_max           -7.57e-06   1.78e-05     -0.425      0.671   -4.25e-05    2.73e-05\n",
       "Total:_min                    -7.801e-05   3.61e-05     -2.160      0.031      -0.000   -7.23e-06\n",
       "Less than $20,000_min          2.857e-05   2.91e-05      0.981      0.326   -2.85e-05    8.56e-05\n",
       "$20,000 to $39,999_min        -6.855e-05   2.78e-05     -2.464      0.014      -0.000    -1.4e-05\n",
       "$40,000 to $59,999_min           -0.0002   8.05e-05     -2.356      0.019      -0.000   -3.18e-05\n",
       "$60,000 to $99,999_min           -0.0002   8.95e-05     -2.230      0.026      -0.000   -2.42e-05\n",
       "$100,000 to $149,999_min         -0.0001   5.82e-05     -2.185      0.029      -0.000   -1.31e-05\n",
       "$150,000 to $199,999_min       1.506e-05    1.3e-05      1.155      0.248   -1.05e-05    4.06e-05\n",
       "$200,000 or more_min          -7.219e-06   1.72e-05     -0.421      0.674   -4.09e-05    2.64e-05\n",
       "less_100m                        -0.0069      0.003     -2.263      0.024      -0.013      -0.001\n",
       "less_500m                        -0.0004      0.001     -0.537      0.591      -0.002       0.001\n",
       "less_1km                          0.0001      0.000      0.352      0.725      -0.001       0.001\n",
       "less_5km                         -0.0001   5.73e-05     -2.610      0.009      -0.000   -3.72e-05\n",
       "less_10km                      4.462e-05   3.83e-05      1.165      0.244   -3.05e-05       0.000\n",
       "less_50km                     -7.708e-05   2.55e-05     -3.028      0.002      -0.000   -2.72e-05\n",
       "class_0                          -0.0005      0.001     -0.771      0.441      -0.002       0.001\n",
       "class_1                          -0.0086      0.010     -0.833      0.405      -0.029       0.012\n",
       "class_10                         -0.0531      0.048     -1.101      0.271      -0.148       0.041\n",
       "class_11                          0.0483      0.036      1.354      0.176      -0.022       0.118\n",
       "class_12                         -0.0676      0.045     -1.492      0.136      -0.157       0.021\n",
       "class_13                          0.0112      0.012      0.920      0.357      -0.013       0.035\n",
       "class_14                         -0.0087      0.048     -0.182      0.856      -0.102       0.085\n",
       "class_15                          0.0187      0.033      0.560      0.575      -0.047       0.084\n",
       "class_16                          0.0168      0.019      0.868      0.385      -0.021       0.055\n",
       "class_17                        6.07e-18   1.99e-16      0.030      0.976   -3.85e-16    3.97e-16\n",
       "class_2                           0.0104      0.004      2.601      0.009       0.003       0.018\n",
       "class_20                         -0.0774      0.283     -0.274      0.784      -0.631       0.476\n",
       "class_22                      -1.727e-16   4.82e-16     -0.358      0.720   -1.12e-15    7.72e-16\n",
       "class_23                          0.0448      0.102      0.441      0.659      -0.155       0.244\n",
       "class_24                          0.0044      0.021      0.209      0.834      -0.037       0.046\n",
       "class_25                          0.0078      0.008      1.030      0.303      -0.007       0.023\n",
       "class_26                          0.0061      0.016      0.386      0.699      -0.025       0.037\n",
       "class_27                         -0.0065      0.028     -0.229      0.819      -0.062       0.049\n",
       "class_28                         -0.0396      0.019     -2.057      0.040      -0.077      -0.002\n",
       "class_29                          0.0094      0.077      0.122      0.903      -0.141       0.160\n",
       "class_3                           0.0013      0.017      0.076      0.940      -0.031       0.034\n",
       "class_31                        2.29e-16   5.33e-16      0.430      0.667   -8.16e-16    1.27e-15\n",
       "class_32                         -0.0192      0.041     -0.465      0.642      -0.100       0.062\n",
       "class_33                         -0.0341      0.087     -0.393      0.694      -0.204       0.136\n",
       "class_34                          0.0730      0.117      0.624      0.532      -0.156       0.302\n",
       "class_35                      -1.389e-17   2.74e-16     -0.051      0.960    -5.5e-16    5.23e-16\n",
       "class_36                          0.0403      0.069      0.581      0.561      -0.096       0.176\n",
       "class_37                          0.0688      0.137      0.504      0.614      -0.199       0.336\n",
       "class_38                       -1.09e-17   5.84e-17     -0.187      0.852   -1.25e-16    1.04e-16\n",
       "class_39                          0.0042      0.001      2.792      0.005       0.001       0.007\n",
       "class_4                           0.0343      0.138      0.249      0.804      -0.236       0.305\n",
       "class_40                         -0.0042      0.004     -1.033      0.302      -0.012       0.004\n",
       "class_41                          0.0021      0.002      1.304      0.192      -0.001       0.005\n",
       "class_42                          0.0097      0.008      1.208      0.227      -0.006       0.026\n",
       "class_43                          0.0079      0.012      0.679      0.497      -0.015       0.031\n",
       "class_44                          0.0004      0.007      0.050      0.960      -0.013       0.014\n",
       "class_45                         -0.0008      0.003     -0.294      0.769      -0.006       0.004\n",
       "class_46                          0.0103      0.011      0.898      0.369      -0.012       0.033\n",
       "class_47                          0.0021      0.018      0.112      0.911      -0.034       0.038\n",
       "class_48                          0.0009      0.004      0.203      0.840      -0.007       0.009\n",
       "class_49                         -0.0033      0.012     -0.269      0.788      -0.028       0.021\n",
       "class_5                           0.1283      0.075      1.704      0.089      -0.019       0.276\n",
       "class_50                          0.0121      0.012      0.966      0.334      -0.012       0.037\n",
       "class_51                         -0.0013      0.009     -0.134      0.893      -0.020       0.017\n",
       "class_52                         -0.0019      0.010     -0.196      0.845      -0.021       0.017\n",
       "class_53                          0.0055      0.008      0.645      0.519      -0.011       0.022\n",
       "class_54                          0.0046      0.002      2.248      0.025       0.001       0.009\n",
       "class_55                          0.0007      0.003      0.226      0.821      -0.006       0.007\n",
       "class_56                       9.049e-05      0.001      0.116      0.908      -0.001       0.002\n",
       "class_57                          0.0041      0.009      0.446      0.656      -0.014       0.022\n",
       "class_58                          0.0019      0.002      0.918      0.359      -0.002       0.006\n",
       "class_59                         -0.0424      0.051     -0.833      0.405      -0.142       0.057\n",
       "class_6                          -0.0339      0.121     -0.281      0.779      -0.270       0.203\n",
       "class_60                          0.0007      0.003      0.210      0.834      -0.006       0.007\n",
       "class_61                         -0.0433      0.036     -1.206      0.228      -0.114       0.027\n",
       "class_62                          0.0074      0.005      1.428      0.153      -0.003       0.018\n",
       "class_63                          0.0141      0.011      1.265      0.206      -0.008       0.036\n",
       "class_64                         -0.1327      0.098     -1.359      0.174      -0.324       0.059\n",
       "class_65                         -0.0204      0.056     -0.366      0.714      -0.130       0.089\n",
       "class_66                          0.1290      0.094      1.374      0.169      -0.055       0.313\n",
       "class_67                          0.0162      0.013      1.219      0.223      -0.010       0.042\n",
       "class_68                          0.0081      0.017      0.470      0.639      -0.026       0.042\n",
       "class_69                         -0.0018      0.018     -0.099      0.921      -0.036       0.033\n",
       "class_7                          -0.0016      0.033     -0.049      0.961      -0.067       0.064\n",
       "class_70                               0          0        nan        nan           0           0\n",
       "class_71                          0.0070      0.025      0.281      0.778      -0.042       0.056\n",
       "class_72                         -0.0014      0.010     -0.142      0.887      -0.021       0.018\n",
       "class_73                          0.0028      0.011      0.250      0.803      -0.019       0.024\n",
       "class_74                         -0.0005      0.009     -0.056      0.956      -0.019       0.018\n",
       "class_75                          0.0027      0.006      0.477      0.633      -0.008       0.014\n",
       "class_76                          0.0107      0.083      0.128      0.898      -0.152       0.173\n",
       "class_77                          0.0281      0.019      1.511      0.131      -0.008       0.065\n",
       "class_79                          0.0002      0.057      0.004      0.997      -0.111       0.112\n",
       "class_8                          -0.0454      0.279     -0.163      0.871      -0.591       0.501\n",
       "class_9                          -0.0092      0.012     -0.796      0.426      -0.032       0.013\n",
       "==============================================================================\n",
       "Omnibus:                      740.783   Durbin-Watson:                   1.933\n",
       "Prob(Omnibus):                  0.000   Jarque-Bera (JB):             2998.072\n",
       "Skew:                          -0.537   Prob(JB):                         0.00\n",
       "Kurtosis:                       6.220   Cond. No.                     3.36e+19\n",
       "==============================================================================\n",
       "\n",
       "Warnings:\n",
       "[1] Standard Errors assume that the covariance matrix of the errors is correctly specified.\n",
       "[2] The smallest eigenvalue is 3.91e-19. This might indicate that there are\n",
       "strong multicollinearity problems or that the design matrix is singular.\n",
       "\"\"\""
      ]
     },
     "execution_count": 250,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X['user_yelp_years'] = X['user_yelp_years'] / np.timedelta64(1, 's')\n",
    "for i in X.columns:\n",
    "    if X[i].dtype == np.object:\n",
    "        X[i] = pd.factorize(X[i])[0]\n",
    "#print(X['state_state'])\n",
    "X.replace([np.inf, -np.inf], 0, inplace=True)\n",
    "X.replace(np.nan, 0, inplace=True)\n",
    "## fit a OLS model with intercept\n",
    "X = sm.add_constant(X)\n",
    "est = sm.OLS(y,X,missing='drop').fit()\n",
    "est.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## --------------------------------------------------------------------------------------------------------"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 251,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/anaconda3/lib/python3.7/site-packages/sklearn/linear_model/_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 5.666e+02, tolerance: 1.407e-01\n",
      "  coef_, l1_reg, l2_reg, X, y, max_iter, tol, rng, random, positive\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "R squared training set 22.44\n",
      "R squared test set 9.89\n",
      "Mean MAE: 0.381 (0.027)\n"
     ]
    }
   ],
   "source": [
    "# lasso - alpha = 1\n",
    "from numpy import mean\n",
    "from numpy import std\n",
    "from numpy import absolute\n",
    "from pandas import read_csv\n",
    "from sklearn.model_selection import cross_val_score\n",
    "from sklearn.model_selection import RepeatedKFold\n",
    "from sklearn.linear_model import Lasso\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "## by sklearn package\n",
    "from sklearn.model_selection import train_test_split\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.25, random_state=10)\n",
    "\n",
    "model = Lasso(alpha=1.0)\n",
    "# define model evaluation method\n",
    "cv = RepeatedKFold(n_splits=10, n_repeats=3, random_state=1)\n",
    "model.fit(X_train, y_train)\n",
    "#print(model.coef_)\n",
    "# evaluate model\n",
    "scores = cross_val_score(model, X_test, y_test, scoring='neg_mean_absolute_error', cv=cv, n_jobs=-1)\n",
    "# force scores to be positive\n",
    "scores = absolute(scores)\n",
    "print('R squared training set', round(model.score(X_train, y_train)*100, 2))\n",
    "print('R squared test set', round(model.score(X_test, y_test)*100, 2))\n",
    "print('Mean MAE: %.3f (%.3f)' % (mean(scores), std(scores)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 252,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "R squared training set 0.0\n",
      "R squared test set -0.02\n",
      "Mean MAE: 0.439 (0.025)\n"
     ]
    }
   ],
   "source": [
    "# lasso - with alpha = 1 & x scaled\n",
    "from numpy import mean\n",
    "from numpy import std\n",
    "from numpy import absolute\n",
    "from pandas import read_csv\n",
    "from sklearn.model_selection import cross_val_score\n",
    "from sklearn.model_selection import RepeatedKFold\n",
    "from sklearn.linear_model import Lasso\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "## by sklearn package\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "sc = StandardScaler()\n",
    "X_scaled = sc.fit_transform(X)\n",
    "X_scaled = pd.DataFrame(data = X_scaled, columns = X.columns)\n",
    "X_train, X_test, y_train, y_test = train_test_split(X_scaled, y, test_size=0.25, random_state=10)\n",
    "\n",
    "model = Lasso(alpha=1.0)\n",
    "# define model evaluation method\n",
    "cv = RepeatedKFold(n_splits=10, n_repeats=3, random_state=1)\n",
    "model.fit(X_train, y_train)\n",
    "#print(model.coef_)\n",
    "# evaluate model\n",
    "scores = cross_val_score(model, X_test, y_test, scoring='neg_mean_absolute_error', cv=cv, n_jobs=-1)\n",
    "# force scores to be positive\n",
    "scores = absolute(scores)\n",
    "print('R squared training set', round(model.score(X_train, y_train)*100, 2))\n",
    "print('R squared test set', round(model.score(X_test, y_test)*100, 2))\n",
    "print('Mean MAE: %.3f (%.3f)' % (mean(scores), std(scores)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "-------------------"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 255,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/anaconda3/lib/python3.7/site-packages/sklearn/linear_model/_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 3.930e+02, tolerance: 1.407e-01\n",
      "  coef_, l1_reg, l2_reg, X, y, max_iter, tol, rng, random, positive\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "R squared training set 68.11\n",
      "R squared test set 66.85\n",
      "Mean MAE: 0.227 (0.017)\n"
     ]
    }
   ],
   "source": [
    "# lasso with alpha = 0.1 \n",
    "from sklearn.model_selection import train_test_split\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.25, random_state=10)\n",
    "\n",
    "from sklearn import linear_model\n",
    "clf = linear_model.Lasso(alpha=0.1)\n",
    "clf.fit(X_train,y_train)\n",
    "\n",
    "print('R squared training set', round(clf.score(X_train, y_train)*100, 2))\n",
    "print('R squared test set', round(clf.score(X_test, y_test)*100, 2))\n",
    "\n",
    "scores = cross_val_score(clf, X_test, y_test, scoring='neg_mean_absolute_error', cv=cv, n_jobs=-1)\n",
    "# force scores to be positive\n",
    "scores = absolute(scores)\n",
    "print('Mean MAE: %.3f (%.3f)' % (mean(scores), std(scores)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 256,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "R squared training set 68.08\n",
      "R squared test set 68.49\n",
      "Mean MAE: 0.222 (0.016)\n"
     ]
    }
   ],
   "source": [
    "# lasso with alpha = 0.1 & x scaled\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "sc = StandardScaler()\n",
    "X_scaled = sc.fit_transform(X)\n",
    "X_scaled = pd.DataFrame(data = X_scaled, columns = X.columns)\n",
    "X_train, X_test, y_train, y_test = train_test_split(X_scaled, y, test_size=0.25, random_state=10)\n",
    "\n",
    "clf = linear_model.Lasso(alpha=0.1)\n",
    "clf.fit(X_train,y_train)\n",
    "\n",
    "print('R squared training set', round(clf.score(X_train, y_train)*100, 2))\n",
    "print('R squared test set', round(clf.score(X_test, y_test)*100, 2))\n",
    "\n",
    "scores = cross_val_score(clf, X_test, y_test, scoring='neg_mean_absolute_error', cv=cv, n_jobs=-1)\n",
    "# force scores to be positive\n",
    "scores = absolute(scores)\n",
    "print('Mean MAE: %.3f (%.3f)' % (mean(scores), std(scores)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 257,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE: -0.19131\n",
      "Config: {'alpha': 0.01}\n"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import KFold, RepeatedKFold, GridSearchCV, cross_validate, train_test_split\n",
    "\n",
    "cv = RepeatedKFold(n_splits=10, n_repeats=3, random_state=1) \n",
    "lasso_alphas = np.linspace(0, 0.2, 21)\n",
    "lasso = Lasso()\n",
    "grid = dict()\n",
    "grid['alpha'] = lasso_alphas \n",
    "gscv = GridSearchCV(lasso, grid, scoring='neg_mean_absolute_error',cv=cv, n_jobs=-1) \n",
    "results = gscv.fit(X_train, y_train)\n",
    "\n",
    "print('MAE: %.5f' % results.best_score_) \n",
    "print('Config: %s' % results.best_params_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 258,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "R squared training set 74.57\n",
      "R squared test set 74.92\n",
      "Mean MAE: 0.188 (0.013)\n"
     ]
    }
   ],
   "source": [
    "# lasso with alpha = 0.1 & x scaled\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "sc = StandardScaler()\n",
    "X_scaled = sc.fit_transform(X)\n",
    "X_scaled = pd.DataFrame(data = X_scaled, columns = X.columns)\n",
    "X_train, X_test, y_train, y_test = train_test_split(X_scaled, y, test_size=0.25, random_state=10)\n",
    "\n",
    "opt_model = linear_model.Lasso(alpha=0.01)\n",
    "opt_model.fit(X_train,y_train)\n",
    "\n",
    "print('R squared training set', round(opt_model.score(X_train, y_train)*100, 2))\n",
    "print('R squared test set', round(opt_model.score(X_test, y_test)*100, 2))\n",
    "\n",
    "scores = cross_val_score(opt_model, X_test, y_test, scoring='neg_mean_absolute_error', cv=cv, n_jobs=-1)\n",
    "# force scores to be positive\n",
    "scores = absolute(scores)\n",
    "print('Mean MAE: %.3f (%.3f)' % (mean(scores), std(scores)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 260,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['rate_user_num', 'state', 'Caters', 'WheelchairAccessible', 'BusinessParking', 'BusinessAcceptsCreditCards', 'rating', 'num_rating', 'photo_drink', 'photo_food', 'user_avg_useful', 'user_avg_total_compliment', 'DENSITY_2021', 'less_500m', 'less_1km', 'less_10km']\n"
     ]
    }
   ],
   "source": [
    "x = ['stars', \n",
    "    'rate_user_num', \n",
    "    'state', \n",
    "    'latitude',\n",
    "    'longitude', \n",
    "    'review_count', \n",
    "    'price_level', \n",
    "    'HasTV', \n",
    "    'Caters', \n",
    "    'OutdoorSeating', \n",
    "    'WheelchairAccessible', \n",
    "    'BusinessParking', \n",
    "    'RestaurantsDelivery', \n",
    "    'BikeParking', \n",
    "    'WiFi', \n",
    "    'Alcohol', \n",
    "    'RestaurantsTakeOut',\n",
    "    'BusinessAcceptsCreditCards', \n",
    "    'open_days', \n",
    "    'open_hours', \n",
    "    'rating', \n",
    "    'num_rating', \n",
    "    'photo_drink', \n",
    "    'photo_food', \n",
    "    'photo_inside', \n",
    "    'photo_menu',\n",
    "    'photo_outside', \n",
    "    'photo_total', \n",
    "    'user_avg_stars', \n",
    "    'user_avg_review_count', \n",
    "    'user_avg_useful', \n",
    "    'user_avg_funny', \n",
    "    'user_avg_cool', \n",
    "    'user_avg_fans', \n",
    "    'user_avg_compliment_hot', \n",
    "    'user_avg_compliment_more', \n",
    "    'user_avg_compliment_profile', \n",
    "    'user_avg_compliment_cute', \n",
    "    'user_avg_compliment_list', \n",
    "    'user_avg_compliment_note', \n",
    "    'user_avg_compliment_plain', \n",
    "    'user_avg_compliment_cool',\n",
    "    'user_avg_compliment_funny', \n",
    "    'user_avg_compliment_writer', \n",
    "    'user_avg_compliment_photos', \n",
    "    'user_yelp_years', \n",
    "    'user_avg_total_compliment',\n",
    "    'state_state', \n",
    "    'abbrev',\n",
    "    'code', \n",
    "    'full_state',\n",
    "    'Total:_Estimate',\n",
    "    'Less than $20,000_Estimate', \n",
    "    '$20,000 to $39,999_Estimate', \n",
    "    '$40,000 to $59,999_Estimate', \n",
    "    '$60,000 to $99,999_Estimate', \n",
    "    '$100,000 to $149,999_Estimate',\n",
    "    '$150,000 to $199,999_Estimate', \n",
    "    '$200,000 or more_Estimate', \n",
    "    'PAYANN', 'PCHDAPR', 'PCHADVT', 'DENSITY_2021', 'POP_2021', \n",
    "    'Total:_max', 'Less than $20,000_max', '$20,000 to $39,999_max', '$40,000 to $59,999_max', \n",
    "    '$60,000 to $99,999_max', '$100,000 to $149,999_max', '$150,000 to $199,999_max', '$200,000 or more_max',\n",
    "    'Total:_min', 'Less than $20,000_min', '$20,000 to $39,999_min', '$40,000 to $59,999_min', \n",
    "    '$60,000 to $99,999_min', '$100,000 to $149,999_min', '$150,000 to $199,999_min', '$200,000 or more_min', \n",
    "    'less_100m', 'less_500m', 'less_1km', 'less_5km', 'less_10km', 'less_50km', \n",
    "    'class_0', 'class_1', 'class_10', 'class_11', 'class_12', 'class_13', 'class_14', 'class_15', \n",
    "    'class_16', 'class_17', 'class_2', 'class_20', 'class_22', 'class_23', 'class_24', 'class_25', \n",
    "    'class_26', 'class_27', 'class_28', 'class_29', 'class_3', 'class_31', 'class_32', 'class_33', \n",
    "    'class_34', 'class_35', 'class_36', 'class_37', 'class_38', 'class_39', 'class_4', 'class_40', \n",
    "    'class_41', 'class_42', 'class_43', 'class_44', 'class_45', 'class_46', 'class_47', 'class_48', \n",
    "    'class_49', 'class_5', 'class_50', 'class_51', 'class_52', 'class_53', 'class_54', 'class_55', \n",
    "    'class_56', 'class_57', 'class_58', 'class_59', 'class_6', 'class_60', 'class_61', 'class_62', \n",
    "    'class_63', 'class_64', 'class_65', 'class_66', 'class_67', 'class_68', 'class_69', 'class_7', \n",
    "    'class_70', 'class_71', 'class_72', 'class_73', 'class_74', 'class_75', 'class_76', 'class_77', \n",
    "    'class_79', 'class_8', 'class_9']\n",
    "coefficient = opt_model.coef_\n",
    "idx = []\n",
    "for index,v in enumerate(coefficient):\n",
    "    if v!=0.00000000e+00 or v!=-0.00000000e+00:\n",
    "        idx.append(index)\n",
    "selected_c = []\n",
    "for i in idx:\n",
    "    selected_c.append(x[i])\n",
    "print(selected_c)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
